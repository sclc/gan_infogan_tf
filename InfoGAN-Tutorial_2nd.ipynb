{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoGAN Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorials walks through an implementation of InfoGAN as described in [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://arxiv.org/abs/1606.03657).\n",
    "\n",
    "To learn more about InfoGAN, see this [Medium post](https://medium.com/p/dd710852db46) on them. To lean more about GANs generally, see [this one](https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39#.692jyamki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the libraries we will need.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import scipy.misc\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function performns a leaky relu activation, which is needed for the discriminator network.\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "     with tf.variable_scope(name):\n",
    "         f1 = 0.5 * (1 + leak)\n",
    "         f2 = 0.5 * (1 - leak)\n",
    "         return f1 * x + f2 * abs(x)\n",
    "    \n",
    "#The below functions are taken from carpdem20's implementation https://github.com/carpedm20/DCGAN-tensorflow\n",
    "#They allow for saving sample images from the generator to follow progress\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network\n",
    "\n",
    "The generator takes a vector of random numbers and transforms it into a 32x32 image. Each layer in the network involves a strided  transpose convolution, batch normalization, and rectified nonlinearity. Tensorflow's slim library allows us to easily define each of these layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    \n",
    "    zP = slim.fully_connected(z,4*4*256,normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_project',weights_initializer=initializer)\n",
    "    zCon = tf.reshape(zP,[-1,4,4,256])\n",
    "    \n",
    "    gen1 = slim.convolution2d(\\\n",
    "        zCon,num_outputs=128,kernel_size=[3,3],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv1', weights_initializer=initializer)\n",
    "    gen1 = tf.depth_to_space(gen1,2)\n",
    "    \n",
    "    gen2 = slim.convolution2d(\\\n",
    "        gen1,num_outputs=64,kernel_size=[3,3],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv2', weights_initializer=initializer)\n",
    "    gen2 = tf.depth_to_space(gen2,2)\n",
    "    \n",
    "    gen3 = slim.convolution2d(\\\n",
    "        gen2,num_outputs=32,kernel_size=[3,3],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv3', weights_initializer=initializer)\n",
    "    gen3 = tf.depth_to_space(gen3,2)\n",
    "    \n",
    "    g_out = slim.convolution2d(\\\n",
    "        gen3,num_outputs=1,kernel_size=[32,32],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=tf.nn.tanh,\\\n",
    "        scope='g_out', weights_initializer=initializer)\n",
    "    \n",
    "    return g_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network\n",
    "The discriminator network takes as input a 32x32 image and transforms it into a single valued probability of being generated from real-world data. Again we use tf.slim to define the convolutional layers, batch normalization, and weight initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminator(bottom, cat_list,conts, reuse=False):\n",
    "    \n",
    "    dis1 = slim.convolution2d(bottom,32,[3,3],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv1',weights_initializer=initializer)\n",
    "    dis1 = tf.space_to_depth(dis1,2)\n",
    "    \n",
    "    dis2 = slim.convolution2d(dis1,64,[3,3],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv2', weights_initializer=initializer)\n",
    "    dis2 = tf.space_to_depth(dis2,2)\n",
    "    \n",
    "    dis3 = slim.convolution2d(dis2,128,[3,3],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv3',weights_initializer=initializer)\n",
    "    dis3 = tf.space_to_depth(dis3,2)\n",
    "        \n",
    "    dis4 = slim.fully_connected(slim.flatten(dis3),1024,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_fc1', weights_initializer=initializer)\n",
    "        \n",
    "    d_out = slim.fully_connected(dis4,1,activation_fn=tf.nn.sigmoid,\\\n",
    "        reuse=reuse,scope='d_out', weights_initializer=initializer)\n",
    "    \n",
    "    q_a = slim.fully_connected(dis4,128,normalizer_fn=slim.batch_norm,\\\n",
    "        reuse=reuse,scope='q_fc1', weights_initializer=initializer)\n",
    "    \n",
    "    \n",
    "    ## Here we define the unique layers used for the q-network. The number of outputs depends on the number of \n",
    "    ## latent variables we choose to define.\n",
    "    q_cat_outs = []\n",
    "    for idx,var in enumerate(cat_list):\n",
    "        q_outA = slim.fully_connected(q_a,var,activation_fn=tf.nn.softmax,\\\n",
    "            reuse=reuse,scope='q_out_cat_'+str(idx), weights_initializer=initializer)\n",
    "        q_cat_outs.append(q_outA)\n",
    "    \n",
    "    q_cont_outs = None\n",
    "    if conts > 0:\n",
    "        q_cont_outs = slim.fully_connected(q_a,conts,activation_fn=tf.nn.tanh,\\\n",
    "            reuse=reuse,scope='q_out_cont_'+str(conts), weights_initializer=initializer)\n",
    "    \n",
    "    return d_out,q_cat_outs,q_cont_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/split\n",
    "# https://www.tensorflow.org/api_docs/python/tf/one_hot\n",
    "# https://www.tensorflow.org/api_docs/python/tf/concat\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "z_size = 64 #Size of initial z vector used for generator.\n",
    "\n",
    "# Define latent variables.\n",
    "categorical_list = [10] # Each entry in this list defines a categorical variable of a specific size.\n",
    "number_continuous = 2 # The number of continous variables.\n",
    "\n",
    "#This initializaer is used to initialize all the weights of the network.\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "#These placeholders are used for input into the generator and discriminator, respectively.\n",
    "z_in = tf.placeholder(shape=[None,z_size],dtype=tf.float32) #Random vector\n",
    "real_in = tf.placeholder(shape=[None,32,32,1],dtype=tf.float32) #Real images\n",
    "\n",
    "#These placeholders load the latent variables.\n",
    "latent_cat_in = tf.placeholder(shape=[None,len(categorical_list)],dtype=tf.int32)\n",
    "latent_cat_list = tf.split(latent_cat_in,len(categorical_list),1)\n",
    "latent_cont_in = tf.placeholder(shape=[None,number_continuous],dtype=tf.float32)\n",
    "\n",
    "oh_list = []\n",
    "for idx,var in enumerate(categorical_list):\n",
    "    latent_oh = tf.one_hot(tf.reshape(latent_cat_list[idx],[-1]),var)\n",
    "    oh_list.append(latent_oh)\n",
    "\n",
    "#Concatenate all c and z variables.\n",
    "z_lats = oh_list[:]\n",
    "z_lats.append(z_in)\n",
    "z_lats.append(latent_cont_in)\n",
    "z_lat = tf.concat(z_lats,1)\n",
    "\n",
    "\n",
    "Gz = generator(z_lat) #Generates images from random z vectors\n",
    "Dx,_,_ = discriminator(real_in,categorical_list,number_continuous) #Produces probabilities for real images\n",
    "Dg,QgCat,QgCont = discriminator(Gz,categorical_list,number_continuous,reuse=True) #Produces probabilities for generator images\n",
    "\n",
    "#These functions together define the optimization objective of the GAN.\n",
    "d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg)) #This optimizes the discriminator.\n",
    "g_loss = -tf.reduce_mean(tf.log((Dg/(1-Dg)))) #KL Divergence optimizer\n",
    "\n",
    "#Combine losses for each of the categorical variables.\n",
    "cat_losses = []\n",
    "for idx,latent_var in enumerate(oh_list):\n",
    "    cat_loss = -tf.reduce_sum(latent_var*tf.log(QgCat[idx]),axis=1)\n",
    "    cat_losses.append(cat_loss)\n",
    "    \n",
    "#Combine losses for each of the continous variables.\n",
    "if number_continuous > 0:\n",
    "    q_cont_loss = tf.reduce_sum(0.5 * tf.square(latent_cont_in - QgCont),axis=1)\n",
    "else:\n",
    "    q_cont_loss = tf.constant(0.0)\n",
    "\n",
    "q_cont_loss = tf.reduce_mean(q_cont_loss)\n",
    "q_cat_loss = tf.reduce_mean(cat_losses)\n",
    "q_loss = tf.add(q_cat_loss,q_cont_loss)\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "#The below code is responsible for applying gradient descent to update the GAN.\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "trainerG = tf.train.AdamOptimizer(learning_rate=0.002,beta1=0.5)\n",
    "trainerQ = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "d_grads = trainerD.compute_gradients(d_loss,tvars[9:-2-((number_continuous>0)*2)-(len(categorical_list)*2)]) #Only update the weights for the discriminator network.\n",
    "g_grads = trainerG.compute_gradients(g_loss, tvars[0:9]) #Only update the weights for the generator network.\n",
    "q_grads = trainerQ.compute_gradients(q_loss, tvars) \n",
    "\n",
    "update_D = trainerD.apply_gradients(d_grads)\n",
    "update_G = trainerG.apply_gradients(g_grads)\n",
    "update_Q = trainerQ.apply_gradients(q_grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training the network\n",
    "Now that we have fully defined our network, it is time to train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen Loss: 3.33437 Disc Loss: 1.54879 Q Losses: [0.36781007, 2.3237472]\n",
      "Gen Loss: 0.540094 Disc Loss: 0.762471 Q Losses: [0.30421865, 2.2572031]\n",
      "Gen Loss: 4.80545 Disc Loss: 2.01615 Q Losses: [0.32420143, 2.2047033]\n",
      "Gen Loss: 1.56394 Disc Loss: 0.512252 Q Losses: [0.32299459, 2.1925797]\n",
      "Gen Loss: 1.69666 Disc Loss: 0.684382 Q Losses: [0.33945966, 2.3065629]\n",
      "Gen Loss: 0.999278 Disc Loss: 0.445453 Q Losses: [0.27503541, 2.0261211]\n",
      "Gen Loss: 1.99587 Disc Loss: 0.916731 Q Losses: [0.27387598, 1.9760774]\n",
      "Gen Loss: 5.71778 Disc Loss: 1.43561 Q Losses: [0.31380883, 1.6982563]\n",
      "Gen Loss: 1.33778 Disc Loss: 0.741529 Q Losses: [0.23610587, 1.2501307]\n",
      "Gen Loss: 1.23776 Disc Loss: 0.732471 Q Losses: [0.26568696, 0.83336985]\n",
      "Gen Loss: -0.30839 Disc Loss: 1.02031 Q Losses: [0.2403959, 0.68542141]\n",
      "Saved Model on  1000\n",
      "Gen Loss: 1.54843 Disc Loss: 0.97604 Q Losses: [0.21266326, 0.60903639]\n",
      "Gen Loss: 1.81042 Disc Loss: 1.01043 Q Losses: [0.23176879, 0.33757824]\n",
      "Gen Loss: 1.25007 Disc Loss: 0.853668 Q Losses: [0.18716724, 0.36398485]\n",
      "Gen Loss: 0.807811 Disc Loss: 0.918922 Q Losses: [0.21704884, 0.43442982]\n",
      "Gen Loss: 1.55306 Disc Loss: 0.832802 Q Losses: [0.18612026, 0.14371933]\n",
      "Gen Loss: 1.20158 Disc Loss: 0.783124 Q Losses: [0.18248153, 0.23487765]\n",
      "Gen Loss: 1.11981 Disc Loss: 0.780067 Q Losses: [0.18944174, 0.174101]\n",
      "Gen Loss: 0.58021 Disc Loss: 1.05314 Q Losses: [0.14702082, 0.37674737]\n",
      "Gen Loss: 2.42008 Disc Loss: 1.06485 Q Losses: [0.1480937, 0.37051654]\n",
      "Gen Loss: -1.10139 Disc Loss: 2.39518 Q Losses: [0.12269066, 0.17458117]\n",
      "Saved Model on  2000\n",
      "Gen Loss: 2.28252 Disc Loss: 0.550489 Q Losses: [0.13973086, 0.10984349]\n",
      "Gen Loss: 1.54937 Disc Loss: 0.965753 Q Losses: [0.11076218, 0.22693728]\n",
      "Gen Loss: -0.272732 Disc Loss: 1.0348 Q Losses: [0.17003757, 0.23274052]\n",
      "Gen Loss: 2.57152 Disc Loss: 0.869703 Q Losses: [0.11954212, 0.24817249]\n",
      "Gen Loss: 1.19384 Disc Loss: 0.860785 Q Losses: [0.13202262, 0.2947444]\n",
      "Gen Loss: 0.351999 Disc Loss: 0.745021 Q Losses: [0.12339288, 0.10454163]\n",
      "Gen Loss: 1.33712 Disc Loss: 0.81626 Q Losses: [0.12370635, 0.11092025]\n",
      "Gen Loss: -0.844609 Disc Loss: 0.990352 Q Losses: [0.1295431, 0.11928146]\n",
      "Gen Loss: 2.25414 Disc Loss: 1.23747 Q Losses: [0.091559708, 0.12611884]\n",
      "Gen Loss: 2.25493 Disc Loss: 1.24273 Q Losses: [0.11905895, 0.053137019]\n",
      "Saved Model on  3000\n",
      "Gen Loss: 1.81019 Disc Loss: 0.821394 Q Losses: [0.11946933, 0.11942779]\n",
      "Gen Loss: 1.2797 Disc Loss: 1.07735 Q Losses: [0.14062645, 0.072642304]\n",
      "Gen Loss: 1.23737 Disc Loss: 0.996079 Q Losses: [0.12719524, 0.081616625]\n",
      "Gen Loss: 1.29971 Disc Loss: 1.00458 Q Losses: [0.10428208, 0.15017828]\n",
      "Gen Loss: 1.89833 Disc Loss: 1.02791 Q Losses: [0.099282697, 0.070420228]\n",
      "Gen Loss: -0.390861 Disc Loss: 1.4961 Q Losses: [0.10580085, 0.093419373]\n",
      "Gen Loss: 1.58087 Disc Loss: 1.11786 Q Losses: [0.064623907, 0.031627208]\n",
      "Gen Loss: 1.33962 Disc Loss: 0.933078 Q Losses: [0.07954666, 0.050920174]\n",
      "Gen Loss: 0.782143 Disc Loss: 1.10106 Q Losses: [0.096715108, 0.074719816]\n",
      "Gen Loss: 0.824042 Disc Loss: 0.936782 Q Losses: [0.12896296, 0.1872109]\n",
      "Saved Model on  4000\n",
      "Gen Loss: 1.62222 Disc Loss: 1.37056 Q Losses: [0.074948616, 0.058325596]\n",
      "Gen Loss: 1.60455 Disc Loss: 0.83641 Q Losses: [0.073319785, 0.065886185]\n",
      "Gen Loss: 1.81485 Disc Loss: 1.17725 Q Losses: [0.075686574, 0.11194135]\n",
      "Gen Loss: 0.91221 Disc Loss: 0.901925 Q Losses: [0.064601168, 0.058569998]\n",
      "Gen Loss: 0.536606 Disc Loss: 0.888149 Q Losses: [0.11014476, 0.036767248]\n",
      "Gen Loss: 0.00726309 Disc Loss: 1.32879 Q Losses: [0.086268984, 0.05209139]\n",
      "Gen Loss: 2.1092 Disc Loss: 1.08325 Q Losses: [0.080066569, 0.14337564]\n",
      "Gen Loss: 2.99767 Disc Loss: 1.38749 Q Losses: [0.082108453, 0.045944598]\n",
      "Gen Loss: 0.968093 Disc Loss: 0.968907 Q Losses: [0.073288724, 0.07153625]\n",
      "Gen Loss: 1.27707 Disc Loss: 0.986905 Q Losses: [0.076846048, 0.10661556]\n",
      "Saved Model on  5000\n",
      "Gen Loss: 3.95392 Disc Loss: 1.5108 Q Losses: [0.089391083, 0.11469656]\n",
      "Gen Loss: 1.28038 Disc Loss: 0.746278 Q Losses: [0.09659265, 0.063705318]\n",
      "Gen Loss: 0.76028 Disc Loss: 1.1194 Q Losses: [0.095268041, 0.014716417]\n",
      "Gen Loss: 2.45776 Disc Loss: 0.981599 Q Losses: [0.067350551, 0.042786062]\n",
      "Gen Loss: -0.0140794 Disc Loss: 0.987864 Q Losses: [0.094020188, 0.019332139]\n",
      "Gen Loss: -0.333668 Disc Loss: 0.912924 Q Losses: [0.077042446, 0.056544423]\n",
      "Gen Loss: 1.18973 Disc Loss: 0.900727 Q Losses: [0.097576454, 0.017915726]\n",
      "Gen Loss: 3.14152 Disc Loss: 1.12923 Q Losses: [0.063222796, 0.021186911]\n",
      "Gen Loss: 1.1391 Disc Loss: 0.885222 Q Losses: [0.059471071, 0.014440401]\n",
      "Gen Loss: 0.659411 Disc Loss: 0.538005 Q Losses: [0.077709615, 0.069820188]\n",
      "Saved Model on  6000\n",
      "Gen Loss: 0.421681 Disc Loss: 1.01374 Q Losses: [0.07898277, 0.14417349]\n",
      "Gen Loss: -1.24624 Disc Loss: 1.52783 Q Losses: [0.093168467, 0.079366766]\n",
      "Gen Loss: 2.6307 Disc Loss: 0.854558 Q Losses: [0.080638543, 0.023662759]\n",
      "Gen Loss: 0.171395 Disc Loss: 1.00762 Q Losses: [0.05493886, 0.026568072]\n",
      "Gen Loss: 0.623479 Disc Loss: 0.807821 Q Losses: [0.071635306, 0.090361059]\n",
      "Gen Loss: 0.0057984 Disc Loss: 1.38541 Q Losses: [0.083541691, 0.016833652]\n",
      "Gen Loss: -0.947523 Disc Loss: 1.51762 Q Losses: [0.07251545, 0.056763384]\n",
      "Gen Loss: 1.44491 Disc Loss: 0.961122 Q Losses: [0.058531534, 0.048497286]\n",
      "Gen Loss: 1.77237 Disc Loss: 0.800487 Q Losses: [0.078779116, 0.017350793]\n",
      "Gen Loss: 1.3144 Disc Loss: 0.918349 Q Losses: [0.050083227, 0.037970938]\n",
      "Saved Model on  7000\n",
      "Gen Loss: -0.0114435 Disc Loss: 1.34885 Q Losses: [0.069735169, 0.077008948]\n",
      "Gen Loss: 2.81883 Disc Loss: 1.19138 Q Losses: [0.05641602, 0.055779133]\n",
      "Gen Loss: -0.341054 Disc Loss: 0.891206 Q Losses: [0.071329445, 0.056907602]\n",
      "Gen Loss: -0.0888851 Disc Loss: 0.997807 Q Losses: [0.08299762, 0.0085700657]\n",
      "Gen Loss: 3.05069 Disc Loss: 0.906329 Q Losses: [0.06082581, 0.0093308883]\n",
      "Gen Loss: 1.77247 Disc Loss: 0.721478 Q Losses: [0.075285494, 0.15200239]\n",
      "Gen Loss: -0.757457 Disc Loss: 1.40606 Q Losses: [0.059056006, 0.045072675]\n",
      "Gen Loss: 1.86231 Disc Loss: 0.713517 Q Losses: [0.068408415, 0.11110853]\n",
      "Gen Loss: 1.80958 Disc Loss: 0.623053 Q Losses: [0.054973304, 0.0067095291]\n",
      "Gen Loss: 2.03472 Disc Loss: 1.14137 Q Losses: [0.053737707, 0.0498816]\n",
      "Saved Model on  8000\n",
      "Gen Loss: 2.15621 Disc Loss: 0.553699 Q Losses: [0.050481886, 0.0048976084]\n",
      "Gen Loss: 3.22005 Disc Loss: 1.24205 Q Losses: [0.060131062, 0.0046474878]\n",
      "Gen Loss: 2.77044 Disc Loss: 0.971201 Q Losses: [0.08489424, 0.0058007375]\n",
      "Gen Loss: -0.293856 Disc Loss: 1.01932 Q Losses: [0.058549985, 0.044346876]\n",
      "Gen Loss: 2.52458 Disc Loss: 1.23835 Q Losses: [0.058428176, 0.052253507]\n",
      "Gen Loss: 0.943745 Disc Loss: 0.6361 Q Losses: [0.063677713, 0.0079350919]\n",
      "Gen Loss: 0.874841 Disc Loss: 0.865359 Q Losses: [0.07339222, 0.001394334]\n",
      "Gen Loss: 0.609337 Disc Loss: 0.928017 Q Losses: [0.061393861, 0.0043518879]\n",
      "Gen Loss: 1.42466 Disc Loss: 0.842329 Q Losses: [0.063612588, 0.027782846]\n",
      "Gen Loss: 1.6734 Disc Loss: 0.760881 Q Losses: [0.054450039, 0.032176688]\n",
      "Saved Model on  9000\n",
      "Gen Loss: 0.097745 Disc Loss: 0.95162 Q Losses: [0.063568965, 0.011251101]\n",
      "Gen Loss: -0.672949 Disc Loss: 1.18486 Q Losses: [0.071587041, 0.0066404566]\n",
      "Gen Loss: 1.30308 Disc Loss: 0.630945 Q Losses: [0.051758878, 0.0065133795]\n",
      "Gen Loss: 3.22331 Disc Loss: 0.679312 Q Losses: [0.069128871, 0.024105899]\n",
      "Gen Loss: 1.99894 Disc Loss: 1.02466 Q Losses: [0.052486103, 0.0069120391]\n",
      "Gen Loss: 1.17078 Disc Loss: 0.791347 Q Losses: [0.065202899, 0.037755527]\n",
      "Gen Loss: 2.24648 Disc Loss: 0.81445 Q Losses: [0.060540698, 0.0055782599]\n",
      "Gen Loss: 2.01608 Disc Loss: 0.683228 Q Losses: [0.059399582, 0.0030004636]\n",
      "Gen Loss: 0.99172 Disc Loss: 0.857576 Q Losses: [0.054581832, 0.011672962]\n",
      "Gen Loss: 0.709948 Disc Loss: 0.708669 Q Losses: [0.051988561, 0.012399569]\n",
      "Saved Model on  10000\n",
      "Gen Loss: 2.16781 Disc Loss: 1.09879 Q Losses: [0.04831104, 0.012735019]\n",
      "Gen Loss: 0.914595 Disc Loss: 0.780922 Q Losses: [0.052427359, 0.026186921]\n",
      "Gen Loss: 2.30986 Disc Loss: 0.932122 Q Losses: [0.062856592, 0.046768084]\n",
      "Gen Loss: 2.06043 Disc Loss: 1.04181 Q Losses: [0.054662846, 0.012956046]\n",
      "Gen Loss: 0.463854 Disc Loss: 0.85933 Q Losses: [0.060417898, 0.0055427421]\n",
      "Gen Loss: 1.16038 Disc Loss: 0.914835 Q Losses: [0.051412519, 0.015213927]\n",
      "Gen Loss: 2.58531 Disc Loss: 0.897973 Q Losses: [0.061701812, 0.047145374]\n",
      "Gen Loss: 3.08672 Disc Loss: 0.894417 Q Losses: [0.047903515, 0.050446972]\n",
      "Gen Loss: -0.211755 Disc Loss: 1.20236 Q Losses: [0.064775527, 0.018106552]\n",
      "Gen Loss: 1.22017 Disc Loss: 0.7503 Q Losses: [0.040382795, 0.00384924]\n",
      "Saved Model on  11000\n",
      "Gen Loss: 2.68678 Disc Loss: 0.995071 Q Losses: [0.060585581, 0.032094341]\n",
      "Gen Loss: 1.55543 Disc Loss: 0.647677 Q Losses: [0.065181844, 0.0015840367]\n",
      "Gen Loss: 1.92206 Disc Loss: 0.768881 Q Losses: [0.068280324, 0.017113367]\n",
      "Gen Loss: 3.61587 Disc Loss: 1.19281 Q Losses: [0.050229821, 0.017597191]\n",
      "Gen Loss: 0.111151 Disc Loss: 1.05839 Q Losses: [0.052868403, 0.0060129464]\n",
      "Gen Loss: 1.26266 Disc Loss: 0.818568 Q Losses: [0.064635925, 0.00092224398]\n",
      "Gen Loss: 0.574989 Disc Loss: 0.710495 Q Losses: [0.057186306, 0.034316242]\n",
      "Gen Loss: 0.345434 Disc Loss: 0.889146 Q Losses: [0.054677762, 0.0019014589]\n",
      "Gen Loss: 2.81646 Disc Loss: 1.08225 Q Losses: [0.055166028, 0.0054241028]\n",
      "Gen Loss: -1.41601 Disc Loss: 1.56455 Q Losses: [0.047833957, 0.023058143]\n",
      "Saved Model on  12000\n",
      "Gen Loss: 1.55248 Disc Loss: 0.741142 Q Losses: [0.029106446, 0.044266976]\n",
      "Gen Loss: 1.69523 Disc Loss: 0.698077 Q Losses: [0.058263544, 0.0022238218]\n",
      "Gen Loss: 2.01675 Disc Loss: 0.70781 Q Losses: [0.049929462, 0.077676587]\n",
      "Gen Loss: 2.32959 Disc Loss: 0.747579 Q Losses: [0.0510014, 0.0058459654]\n",
      "Gen Loss: -1.1007 Disc Loss: 1.60259 Q Losses: [0.050697468, 0.0033594456]\n",
      "Gen Loss: 2.96975 Disc Loss: 0.810839 Q Losses: [0.064107716, 0.08427076]\n",
      "Gen Loss: 2.59652 Disc Loss: 0.733784 Q Losses: [0.053305157, 0.003740679]\n",
      "Gen Loss: 1.04395 Disc Loss: 0.856423 Q Losses: [0.05561769, 0.019504491]\n",
      "Gen Loss: -0.948147 Disc Loss: 2.16291 Q Losses: [0.057348158, 0.0021216306]\n",
      "Gen Loss: 2.40736 Disc Loss: 1.19703 Q Losses: [0.052946001, 0.01204561]\n",
      "Saved Model on  13000\n",
      "Gen Loss: 1.28342 Disc Loss: 0.631696 Q Losses: [0.044173911, 0.0021146007]\n",
      "Gen Loss: -0.0755374 Disc Loss: 1.22851 Q Losses: [0.038328417, 0.0031199544]\n",
      "Gen Loss: 1.14418 Disc Loss: 0.986073 Q Losses: [0.040615849, 0.0012272851]\n",
      "Gen Loss: 2.33346 Disc Loss: 0.90873 Q Losses: [0.050006494, 0.10875836]\n",
      "Gen Loss: 0.579114 Disc Loss: 0.665673 Q Losses: [0.048682734, 0.034134891]\n",
      "Gen Loss: 0.484051 Disc Loss: 1.10703 Q Losses: [0.05578544, 0.042917289]\n",
      "Gen Loss: 1.52939 Disc Loss: 0.618856 Q Losses: [0.064226933, 0.0020069794]\n",
      "Gen Loss: 1.19742 Disc Loss: 0.87266 Q Losses: [0.044785887, 0.022273922]\n",
      "Gen Loss: 1.07659 Disc Loss: 0.667585 Q Losses: [0.062490869, 0.0054003811]\n",
      "Gen Loss: 1.67201 Disc Loss: 0.741459 Q Losses: [0.057166867, 0.010441816]\n",
      "Saved Model on  14000\n",
      "Gen Loss: 2.4687 Disc Loss: 0.809756 Q Losses: [0.039705005, 0.0023566824]\n",
      "Gen Loss: 2.92956 Disc Loss: 1.02947 Q Losses: [0.051410507, 0.032570779]\n",
      "Gen Loss: 3.25174 Disc Loss: 1.04836 Q Losses: [0.05324503, 0.0018671147]\n",
      "Gen Loss: 1.11644 Disc Loss: 0.585199 Q Losses: [0.056454293, 0.091656342]\n",
      "Gen Loss: 0.994965 Disc Loss: 0.963776 Q Losses: [0.057009775, 0.031342782]\n",
      "Gen Loss: 1.30079 Disc Loss: 0.677798 Q Losses: [0.049340051, 0.010504032]\n",
      "Gen Loss: 0.148674 Disc Loss: 1.00028 Q Losses: [0.056422926, 0.022306537]\n",
      "Gen Loss: 1.82901 Disc Loss: 0.669587 Q Losses: [0.04471831, 0.001313193]\n",
      "Gen Loss: 1.31568 Disc Loss: 0.608939 Q Losses: [0.045234442, 0.0063208202]\n",
      "Gen Loss: -0.159554 Disc Loss: 0.731417 Q Losses: [0.057093762, 0.036461517]\n",
      "Saved Model on  15000\n",
      "Gen Loss: 0.706971 Disc Loss: 1.07202 Q Losses: [0.042389572, 0.0043804594]\n",
      "Gen Loss: 6.61006 Disc Loss: 2.75286 Q Losses: [0.03890691, 0.054201491]\n",
      "Gen Loss: 2.15662 Disc Loss: 0.824945 Q Losses: [0.040854219, 0.0022386259]\n",
      "Gen Loss: 1.07845 Disc Loss: 0.703546 Q Losses: [0.04996226, 0.00038752519]\n",
      "Gen Loss: 4.36925 Disc Loss: 1.05332 Q Losses: [0.044167593, 0.026824391]\n",
      "Gen Loss: 1.66916 Disc Loss: 0.708209 Q Losses: [0.073222488, 0.023718629]\n",
      "Gen Loss: 0.380742 Disc Loss: 1.0111 Q Losses: [0.068552688, 0.0019235915]\n",
      "Gen Loss: 2.53317 Disc Loss: 0.8551 Q Losses: [0.051045835, 0.011385279]\n",
      "Gen Loss: -0.376581 Disc Loss: 1.63186 Q Losses: [0.045714781, 0.00059399637]\n",
      "Gen Loss: 1.74764 Disc Loss: 0.473165 Q Losses: [0.04152387, 0.0071868943]\n",
      "Saved Model on  16000\n",
      "Gen Loss: 1.69298 Disc Loss: 0.681995 Q Losses: [0.07445246, 0.0079500256]\n",
      "Gen Loss: 0.785903 Disc Loss: 0.723562 Q Losses: [0.04589469, 0.0085658235]\n",
      "Gen Loss: 0.520184 Disc Loss: 0.991171 Q Losses: [0.050225489, 0.081471771]\n",
      "Gen Loss: 0.544558 Disc Loss: 0.728126 Q Losses: [0.067004621, 0.015775239]\n",
      "Gen Loss: 1.86584 Disc Loss: 0.771311 Q Losses: [0.053775329, 0.0039060737]\n",
      "Gen Loss: 0.329925 Disc Loss: 0.904529 Q Losses: [0.037921838, 0.0016310094]\n",
      "Gen Loss: -0.481378 Disc Loss: 0.975194 Q Losses: [0.052819867, 0.03313648]\n",
      "Gen Loss: 3.055 Disc Loss: 1.23235 Q Losses: [0.070437096, 0.011237236]\n",
      "Gen Loss: 0.841661 Disc Loss: 0.754061 Q Losses: [0.051893987, 0.059280358]\n",
      "Gen Loss: 0.678121 Disc Loss: 0.789767 Q Losses: [0.049113765, 0.055343308]\n",
      "Saved Model on  17000\n",
      "Gen Loss: 2.59986 Disc Loss: 0.728297 Q Losses: [0.046025522, 0.030301429]\n",
      "Gen Loss: -0.0599719 Disc Loss: 1.12936 Q Losses: [0.049799256, 0.0067973724]\n",
      "Gen Loss: 2.10507 Disc Loss: 0.601254 Q Losses: [0.047492217, 0.0086664939]\n",
      "Gen Loss: 2.90413 Disc Loss: 0.793578 Q Losses: [0.044253156, 0.0010044638]\n",
      "Gen Loss: -0.287682 Disc Loss: 1.8213 Q Losses: [0.03549441, 0.0021300288]\n",
      "Gen Loss: 1.63135 Disc Loss: 0.555016 Q Losses: [0.057443433, 0.0018142387]\n",
      "Gen Loss: 1.06691 Disc Loss: 0.706467 Q Losses: [0.038718894, 0.015226441]\n",
      "Gen Loss: 1.42768 Disc Loss: 0.585806 Q Losses: [0.042734981, 0.014381928]\n",
      "Gen Loss: 2.38191 Disc Loss: 0.812001 Q Losses: [0.045987695, 0.012197097]\n",
      "Gen Loss: 1.74344 Disc Loss: 0.905854 Q Losses: [0.041712217, 0.014919441]\n",
      "Saved Model on  18000\n",
      "Gen Loss: 1.13201 Disc Loss: 0.625066 Q Losses: [0.04128129, 0.17008451]\n",
      "Gen Loss: 3.04013 Disc Loss: 0.86418 Q Losses: [0.032515589, 0.00080603163]\n",
      "Gen Loss: 3.26077 Disc Loss: 0.857744 Q Losses: [0.046366394, 0.0014427878]\n",
      "Gen Loss: 5.04596 Disc Loss: 1.49444 Q Losses: [0.036442153, 0.0073716771]\n",
      "Gen Loss: 2.68163 Disc Loss: 0.773848 Q Losses: [0.047781482, 0.025732283]\n",
      "Gen Loss: 0.850893 Disc Loss: 0.803315 Q Losses: [0.046404246, 0.0016742653]\n",
      "Gen Loss: 3.04354 Disc Loss: 1.1847 Q Losses: [0.045582544, 0.0014334189]\n",
      "Gen Loss: 1.80163 Disc Loss: 0.728363 Q Losses: [0.052174121, 0.017510846]\n",
      "Gen Loss: 1.18361 Disc Loss: 0.841376 Q Losses: [0.047030158, 0.019972591]\n",
      "Gen Loss: -0.241961 Disc Loss: 0.924498 Q Losses: [0.04699564, 0.016074745]\n",
      "Saved Model on  19000\n",
      "Gen Loss: 1.18714 Disc Loss: 1.55843 Q Losses: [0.039275158, 0.085724995]\n",
      "Gen Loss: 1.83005 Disc Loss: 0.755007 Q Losses: [0.050253686, 0.024302376]\n",
      "Gen Loss: 2.96092 Disc Loss: 1.11859 Q Losses: [0.072630912, 0.0073450189]\n",
      "Gen Loss: 1.95046 Disc Loss: 0.686828 Q Losses: [0.037039183, 0.013446411]\n",
      "Gen Loss: 1.18855 Disc Loss: 0.761631 Q Losses: [0.036239918, 0.017945047]\n",
      "Gen Loss: 0.0881581 Disc Loss: 1.24562 Q Losses: [0.059417948, 0.009040012]\n",
      "Gen Loss: 1.0793 Disc Loss: 0.553418 Q Losses: [0.051549003, 0.0036175947]\n",
      "Gen Loss: 3.23882 Disc Loss: 1.14892 Q Losses: [0.052312437, 0.0031373445]\n",
      "Gen Loss: 3.04249 Disc Loss: 0.951003 Q Losses: [0.036566529, 0.015033755]\n",
      "Gen Loss: 3.00835 Disc Loss: 0.645007 Q Losses: [0.039043795, 0.034418732]\n",
      "Saved Model on  20000\n",
      "Gen Loss: 1.06496 Disc Loss: 0.938014 Q Losses: [0.050321244, 0.012711728]\n",
      "Gen Loss: 0.942927 Disc Loss: 0.759059 Q Losses: [0.037765078, 0.00070864148]\n",
      "Gen Loss: -0.681221 Disc Loss: 0.878773 Q Losses: [0.060198557, 0.10080849]\n",
      "Gen Loss: -0.0466717 Disc Loss: 1.05796 Q Losses: [0.040077861, 0.0036221216]\n",
      "Gen Loss: 2.21167 Disc Loss: 0.856575 Q Losses: [0.037348997, 0.00075821846]\n",
      "Gen Loss: 2.52813 Disc Loss: 0.422197 Q Losses: [0.046493717, 0.010188923]\n",
      "Gen Loss: 0.224557 Disc Loss: 0.76463 Q Losses: [0.039988361, 0.0011843415]\n",
      "Gen Loss: 1.77572 Disc Loss: 0.540838 Q Losses: [0.048064306, 0.0047725835]\n",
      "Gen Loss: -0.877039 Disc Loss: 0.855235 Q Losses: [0.040383536, 0.0063026543]\n",
      "Gen Loss: 1.68665 Disc Loss: 0.646946 Q Losses: [0.035130128, 0.0012448227]\n",
      "Saved Model on  21000\n",
      "Gen Loss: 2.0501 Disc Loss: 0.551814 Q Losses: [0.038049825, 0.0008964396]\n",
      "Gen Loss: 0.676294 Disc Loss: 0.867061 Q Losses: [0.040320501, 0.0016630015]\n",
      "Gen Loss: 2.61153 Disc Loss: 0.800483 Q Losses: [0.03494893, 0.005757913]\n",
      "Gen Loss: 1.76156 Disc Loss: 0.674086 Q Losses: [0.041754793, 0.001813787]\n",
      "Gen Loss: 1.80224 Disc Loss: 0.701469 Q Losses: [0.044794232, 0.023382081]\n",
      "Gen Loss: 1.88161 Disc Loss: 0.649876 Q Losses: [0.044641688, 0.039146215]\n",
      "Gen Loss: 2.86596 Disc Loss: 0.630738 Q Losses: [0.031251214, 0.0043855235]\n",
      "Gen Loss: 1.84948 Disc Loss: 0.612385 Q Losses: [0.032002114, 0.0057740859]\n",
      "Gen Loss: 0.913479 Disc Loss: 0.989797 Q Losses: [0.044269212, 0.00092370796]\n",
      "Gen Loss: 0.82501 Disc Loss: 0.635589 Q Losses: [0.04051654, 0.014076052]\n",
      "Saved Model on  22000\n",
      "Gen Loss: 3.19176 Disc Loss: 0.868397 Q Losses: [0.07115981, 0.032209173]\n",
      "Gen Loss: 1.88242 Disc Loss: 0.59064 Q Losses: [0.041653324, 0.01347613]\n",
      "Gen Loss: 2.18026 Disc Loss: 0.606984 Q Losses: [0.060565136, 0.011049636]\n",
      "Gen Loss: 2.08375 Disc Loss: 0.656164 Q Losses: [0.048163295, 0.012549071]\n",
      "Gen Loss: 2.1975 Disc Loss: 0.822657 Q Losses: [0.047470871, 0.0052701673]\n",
      "Gen Loss: 1.33312 Disc Loss: 0.860096 Q Losses: [0.068827823, 0.0024492862]\n",
      "Gen Loss: -0.427923 Disc Loss: 0.851937 Q Losses: [0.049115252, 0.021241194]\n",
      "Gen Loss: 1.3227 Disc Loss: 0.670063 Q Losses: [0.046831638, 0.1036908]\n",
      "Gen Loss: 0.739708 Disc Loss: 0.979496 Q Losses: [0.049388491, 0.023599766]\n",
      "Gen Loss: 3.09612 Disc Loss: 0.862752 Q Losses: [0.044472583, 0.0028169181]\n",
      "Saved Model on  23000\n",
      "Gen Loss: 0.551372 Disc Loss: 0.830005 Q Losses: [0.04418714, 0.0062378929]\n",
      "Gen Loss: 3.14572 Disc Loss: 0.768644 Q Losses: [0.036560226, 0.05218818]\n",
      "Gen Loss: 3.10865 Disc Loss: 0.818136 Q Losses: [0.036018435, 0.0088707553]\n",
      "Gen Loss: -0.112497 Disc Loss: 0.958698 Q Losses: [0.050604399, 0.0013876914]\n",
      "Gen Loss: 2.28732 Disc Loss: 0.503224 Q Losses: [0.038383491, 0.0071136709]\n",
      "Gen Loss: 0.943455 Disc Loss: 0.737833 Q Losses: [0.048775904, 0.0079610804]\n",
      "Gen Loss: 2.60033 Disc Loss: 0.605368 Q Losses: [0.047388054, 0.010694711]\n",
      "Gen Loss: 0.844746 Disc Loss: 0.703931 Q Losses: [0.03041734, 0.026658075]\n",
      "Gen Loss: 3.95968 Disc Loss: 0.999301 Q Losses: [0.039235659, 0.0026332925]\n",
      "Gen Loss: 2.81869 Disc Loss: 0.392805 Q Losses: [0.04766959, 0.036238845]\n",
      "Saved Model on  24000\n",
      "Gen Loss: 2.62725 Disc Loss: 0.468918 Q Losses: [0.050478362, 0.0038778174]\n",
      "Gen Loss: 2.31824 Disc Loss: 0.593656 Q Losses: [0.039133884, 0.019842541]\n",
      "Gen Loss: 1.73349 Disc Loss: 0.702012 Q Losses: [0.048358969, 0.0020168272]\n",
      "Gen Loss: 2.22917 Disc Loss: 0.362514 Q Losses: [0.050104, 0.052398033]\n",
      "Gen Loss: 1.52689 Disc Loss: 0.658813 Q Losses: [0.03174679, 0.0015229818]\n",
      "Gen Loss: 4.4673 Disc Loss: 0.868283 Q Losses: [0.045099981, 0.0015609557]\n",
      "Gen Loss: 3.62189 Disc Loss: 0.666851 Q Losses: [0.041399546, 0.0018969345]\n",
      "Gen Loss: 2.63191 Disc Loss: 0.32258 Q Losses: [0.04275839, 0.010836184]\n",
      "Gen Loss: 1.65538 Disc Loss: 1.02562 Q Losses: [0.041839547, 0.055397447]\n",
      "Gen Loss: 2.10039 Disc Loss: 0.418993 Q Losses: [0.054642625, 0.0060606617]\n",
      "Saved Model on  25000\n",
      "Gen Loss: 2.52774 Disc Loss: 0.536117 Q Losses: [0.041691624, 0.017609486]\n",
      "Gen Loss: 1.49544 Disc Loss: 0.642874 Q Losses: [0.044877358, 0.0068098623]\n",
      "Gen Loss: 0.951637 Disc Loss: 0.678211 Q Losses: [0.054998513, 0.026559191]\n",
      "Gen Loss: 5.36062 Disc Loss: 1.13166 Q Losses: [0.038630165, 0.0021430515]\n",
      "Gen Loss: 2.8667 Disc Loss: 0.521669 Q Losses: [0.043168157, 0.0033824905]\n",
      "Gen Loss: 2.03249 Disc Loss: 0.486666 Q Losses: [0.043817159, 0.002052279]\n",
      "Gen Loss: 1.81396 Disc Loss: 0.476935 Q Losses: [0.045761101, 0.052793372]\n",
      "Gen Loss: 2.94724 Disc Loss: 0.681494 Q Losses: [0.038581964, 0.017478699]\n",
      "Gen Loss: 4.41478 Disc Loss: 1.1475 Q Losses: [0.051912285, 0.027916418]\n",
      "Gen Loss: 2.78201 Disc Loss: 0.65558 Q Losses: [0.048211489, 0.00044755469]\n",
      "Saved Model on  26000\n",
      "Gen Loss: 1.58011 Disc Loss: 0.48636 Q Losses: [0.042150117, 0.0027622192]\n",
      "Gen Loss: 2.21142 Disc Loss: 0.312231 Q Losses: [0.037643287, 0.0020038441]\n",
      "Gen Loss: 1.67883 Disc Loss: 0.696553 Q Losses: [0.036794305, 0.060942452]\n",
      "Gen Loss: 2.54053 Disc Loss: 0.881084 Q Losses: [0.04529684, 0.0038092639]\n",
      "Gen Loss: 1.24248 Disc Loss: 1.05517 Q Losses: [0.035153292, 0.064979188]\n",
      "Gen Loss: 3.30923 Disc Loss: 0.45981 Q Losses: [0.042808972, 0.050739899]\n",
      "Gen Loss: 2.40826 Disc Loss: 0.612638 Q Losses: [0.046311043, 0.014476841]\n",
      "Gen Loss: 2.96011 Disc Loss: 0.504214 Q Losses: [0.042013768, 0.0046048742]\n",
      "Gen Loss: 1.72072 Disc Loss: 0.45208 Q Losses: [0.044676449, 0.081523478]\n",
      "Gen Loss: 4.27872 Disc Loss: 0.468968 Q Losses: [0.040156364, 0.076693192]\n",
      "Saved Model on  27000\n",
      "Gen Loss: 2.42155 Disc Loss: 0.420503 Q Losses: [0.044211544, 0.036399193]\n",
      "Gen Loss: 2.56591 Disc Loss: 0.424815 Q Losses: [0.042557485, 0.0010142762]\n",
      "Gen Loss: 1.63157 Disc Loss: 0.531532 Q Losses: [0.035647526, 0.00053189276]\n",
      "Gen Loss: 4.03381 Disc Loss: 0.549558 Q Losses: [0.037737053, 0.029681725]\n",
      "Gen Loss: 2.56265 Disc Loss: 0.520865 Q Losses: [0.037606686, 0.028429272]\n",
      "Gen Loss: 2.52397 Disc Loss: 0.584299 Q Losses: [0.041087341, 0.0041884752]\n",
      "Gen Loss: 1.78614 Disc Loss: 0.389544 Q Losses: [0.047661446, 0.021613298]\n",
      "Gen Loss: 3.29126 Disc Loss: 0.648728 Q Losses: [0.02874673, 0.031565893]\n",
      "Gen Loss: 1.88733 Disc Loss: 0.655461 Q Losses: [0.043219965, 0.13043973]\n",
      "Gen Loss: 2.95851 Disc Loss: 0.439372 Q Losses: [0.030950094, 0.09083055]\n",
      "Saved Model on  28000\n",
      "Gen Loss: 2.59186 Disc Loss: 0.653019 Q Losses: [0.05164665, 0.0010032029]\n",
      "Gen Loss: 2.2759 Disc Loss: 0.633425 Q Losses: [0.052652311, 0.0019697042]\n",
      "Gen Loss: 0.791955 Disc Loss: 0.611611 Q Losses: [0.070237912, 0.0094165038]\n",
      "Gen Loss: 1.80326 Disc Loss: 0.529932 Q Losses: [0.03821364, 0.028730506]\n",
      "Gen Loss: 2.50465 Disc Loss: 0.346573 Q Losses: [0.032073587, 0.00076822384]\n",
      "Gen Loss: 3.75306 Disc Loss: 0.651944 Q Losses: [0.035403784, 0.00041285512]\n",
      "Gen Loss: 3.00987 Disc Loss: 0.351784 Q Losses: [0.049220908, 0.0092466976]\n",
      "Gen Loss: 1.77111 Disc Loss: 1.02368 Q Losses: [0.033616237, 0.0031904117]\n",
      "Gen Loss: 1.95059 Disc Loss: 0.564659 Q Losses: [0.044859111, 0.0069549391]\n",
      "Gen Loss: 4.59112 Disc Loss: 0.722441 Q Losses: [0.038360734, 0.00288655]\n",
      "Saved Model on  29000\n",
      "Gen Loss: 3.47289 Disc Loss: 0.569717 Q Losses: [0.037171304, 0.00061864237]\n",
      "Gen Loss: 2.97855 Disc Loss: 0.441777 Q Losses: [0.042808603, 0.0072167069]\n",
      "Gen Loss: 3.42643 Disc Loss: 0.408154 Q Losses: [0.039793886, 0.0060415566]\n",
      "Gen Loss: 3.35924 Disc Loss: 0.546247 Q Losses: [0.027164992, 0.00056072604]\n",
      "Gen Loss: 1.18168 Disc Loss: 0.770096 Q Losses: [0.046182595, 0.0044016126]\n",
      "Gen Loss: 1.24205 Disc Loss: 0.937729 Q Losses: [0.043461017, 0.010629172]\n",
      "Gen Loss: 2.42253 Disc Loss: 0.630237 Q Losses: [0.035438508, 0.035254531]\n",
      "Gen Loss: -0.561739 Disc Loss: 1.11428 Q Losses: [0.053188138, 0.006430102]\n",
      "Gen Loss: 2.20649 Disc Loss: 0.604561 Q Losses: [0.054798849, 0.0079169003]\n",
      "Gen Loss: 1.88753 Disc Loss: 0.74399 Q Losses: [0.037597954, 0.072060615]\n",
      "Saved Model on  30000\n",
      "Gen Loss: 4.6326 Disc Loss: 1.02457 Q Losses: [0.029351419, 0.022105776]\n",
      "Gen Loss: 1.60855 Disc Loss: 0.770409 Q Losses: [0.042652182, 0.02742446]\n",
      "Gen Loss: 3.2851 Disc Loss: 0.512424 Q Losses: [0.040034398, 0.007933056]\n",
      "Gen Loss: 2.17542 Disc Loss: 0.695252 Q Losses: [0.048569027, 0.0033899224]\n",
      "Gen Loss: 4.39168 Disc Loss: 1.09983 Q Losses: [0.043203238, 0.025416993]\n",
      "Gen Loss: 3.90896 Disc Loss: 0.563132 Q Losses: [0.046726089, 0.0065465001]\n",
      "Gen Loss: 2.71059 Disc Loss: 0.700558 Q Losses: [0.046224639, 0.00075890071]\n",
      "Gen Loss: 3.02377 Disc Loss: 0.404822 Q Losses: [0.04225051, 0.0043139155]\n",
      "Gen Loss: 2.93618 Disc Loss: 0.710109 Q Losses: [0.042426791, 0.0047093667]\n",
      "Gen Loss: 0.530363 Disc Loss: 1.07112 Q Losses: [0.043205041, 0.055533312]\n",
      "Saved Model on  31000\n",
      "Gen Loss: 0.985802 Disc Loss: 0.582937 Q Losses: [0.042641506, 0.0015854799]\n",
      "Gen Loss: 4.03808 Disc Loss: 0.845628 Q Losses: [0.034305133, 0.0066939089]\n",
      "Gen Loss: 2.05382 Disc Loss: 0.775823 Q Losses: [0.041640297, 0.00089312572]\n",
      "Gen Loss: 3.82411 Disc Loss: 0.374212 Q Losses: [0.039584652, 0.0015061448]\n",
      "Gen Loss: 2.52916 Disc Loss: 0.686837 Q Losses: [0.040267125, 0.0125452]\n",
      "Gen Loss: 1.87148 Disc Loss: 0.67032 Q Losses: [0.0346734, 0.028407058]\n",
      "Gen Loss: 1.38042 Disc Loss: 0.734714 Q Losses: [0.042056289, 0.034041688]\n",
      "Gen Loss: 1.08731 Disc Loss: 0.750616 Q Losses: [0.035164181, 0.0029122531]\n",
      "Gen Loss: 2.79473 Disc Loss: 0.500776 Q Losses: [0.042457055, 0.029021161]\n",
      "Gen Loss: 4.30884 Disc Loss: 0.923937 Q Losses: [0.037604295, 0.00037283619]\n",
      "Saved Model on  32000\n",
      "Gen Loss: 0.459888 Disc Loss: 0.631327 Q Losses: [0.042401776, 0.022094062]\n",
      "Gen Loss: 2.9083 Disc Loss: 0.556281 Q Losses: [0.046598602, 0.02489695]\n",
      "Gen Loss: 4.17365 Disc Loss: 0.487457 Q Losses: [0.041228808, 0.0017837343]\n",
      "Gen Loss: 1.66151 Disc Loss: 0.497647 Q Losses: [0.039215412, 0.089696951]\n",
      "Gen Loss: 4.81755 Disc Loss: 0.700329 Q Losses: [0.029905016, 0.0063004745]\n",
      "Gen Loss: 4.30201 Disc Loss: 0.583067 Q Losses: [0.056433607, 0.00060240255]\n",
      "Gen Loss: 2.4063 Disc Loss: 0.344262 Q Losses: [0.048999883, 0.083296522]\n",
      "Gen Loss: 4.28257 Disc Loss: 0.515368 Q Losses: [0.045768358, 0.0068489444]\n",
      "Gen Loss: -0.122333 Disc Loss: 0.676396 Q Losses: [0.047941744, 0.0050905868]\n",
      "Gen Loss: 2.82214 Disc Loss: 0.440857 Q Losses: [0.038021624, 0.002221101]\n",
      "Saved Model on  33000\n",
      "Gen Loss: 1.25798 Disc Loss: 0.668925 Q Losses: [0.055221524, 0.045182258]\n",
      "Gen Loss: 4.82035 Disc Loss: 0.633296 Q Losses: [0.037188374, 0.0022572605]\n",
      "Gen Loss: 3.83213 Disc Loss: 0.89202 Q Losses: [0.045402467, 0.003529903]\n",
      "Gen Loss: 0.878054 Disc Loss: 0.757902 Q Losses: [0.039296102, 0.14123154]\n",
      "Gen Loss: 2.94804 Disc Loss: 0.387826 Q Losses: [0.041439056, 0.00065270136]\n",
      "Gen Loss: 0.875478 Disc Loss: 0.64999 Q Losses: [0.052569494, 0.0031946148]\n",
      "Gen Loss: 3.01781 Disc Loss: 0.656464 Q Losses: [0.042113949, 0.00051523698]\n",
      "Gen Loss: 2.83878 Disc Loss: 0.33448 Q Losses: [0.041274343, 0.0031150377]\n",
      "Gen Loss: 2.77138 Disc Loss: 0.390708 Q Losses: [0.036103226, 0.0013421413]\n",
      "Gen Loss: 5.78472 Disc Loss: 0.495102 Q Losses: [0.061474349, 0.02289754]\n",
      "Saved Model on  34000\n",
      "Gen Loss: 4.37736 Disc Loss: 0.417561 Q Losses: [0.044165187, 0.043609917]\n",
      "Gen Loss: 2.54475 Disc Loss: 0.67213 Q Losses: [0.032658126, 0.0060553397]\n",
      "Gen Loss: 3.30249 Disc Loss: 0.717215 Q Losses: [0.03951472, 0.0059939483]\n",
      "Gen Loss: 2.56176 Disc Loss: 0.45317 Q Losses: [0.042698655, 0.0010510706]\n",
      "Gen Loss: 3.81421 Disc Loss: 0.597419 Q Losses: [0.047344506, 0.010657785]\n",
      "Gen Loss: 1.94402 Disc Loss: 1.00975 Q Losses: [0.046782184, 0.003622649]\n",
      "Gen Loss: 3.90217 Disc Loss: 0.461378 Q Losses: [0.038104914, 0.014082248]\n",
      "Gen Loss: 4.41871 Disc Loss: 0.62358 Q Losses: [0.039334483, 0.010687038]\n",
      "Gen Loss: 2.09915 Disc Loss: 0.408148 Q Losses: [0.057640135, 0.0088928584]\n",
      "Gen Loss: 2.88548 Disc Loss: 0.621599 Q Losses: [0.042148419, 0.0020930478]\n",
      "Saved Model on  35000\n",
      "Gen Loss: 3.80275 Disc Loss: 0.565266 Q Losses: [0.040076561, 0.0011296415]\n",
      "Gen Loss: 1.92735 Disc Loss: 0.403771 Q Losses: [0.040381741, 0.0025740466]\n",
      "Gen Loss: 0.88342 Disc Loss: 0.83207 Q Losses: [0.035833627, 0.0038506195]\n",
      "Gen Loss: 1.01798 Disc Loss: 0.616711 Q Losses: [0.035020869, 0.014769398]\n",
      "Gen Loss: 6.63325 Disc Loss: 1.6371 Q Losses: [0.032041356, 0.0023241544]\n",
      "Gen Loss: -0.373676 Disc Loss: 2.50297 Q Losses: [0.043819118, 0.0020481059]\n",
      "Gen Loss: 2.08579 Disc Loss: 0.420262 Q Losses: [0.033961371, 0.0054115085]\n",
      "Gen Loss: 3.12777 Disc Loss: 0.376199 Q Losses: [0.037113458, 0.017582487]\n",
      "Gen Loss: -0.19139 Disc Loss: 0.776274 Q Losses: [0.045794867, 0.0024670637]\n",
      "Gen Loss: 3.16148 Disc Loss: 0.314449 Q Losses: [0.049992669, 0.00022030664]\n",
      "Saved Model on  36000\n",
      "Gen Loss: 3.33564 Disc Loss: 0.300931 Q Losses: [0.03244181, 0.0058670286]\n",
      "Gen Loss: 3.43387 Disc Loss: 0.506525 Q Losses: [0.038040832, 0.00063318748]\n",
      "Gen Loss: 2.48004 Disc Loss: 0.461847 Q Losses: [0.024939362, 0.0032555538]\n",
      "Gen Loss: 5.28717 Disc Loss: 0.76485 Q Losses: [0.0426565, 0.0017959409]\n",
      "Gen Loss: 2.98162 Disc Loss: 0.717936 Q Losses: [0.033897392, 0.026100298]\n",
      "Gen Loss: 4.23107 Disc Loss: 0.469422 Q Losses: [0.035604235, 0.024257068]\n",
      "Gen Loss: 1.97208 Disc Loss: 0.318097 Q Losses: [0.037463348, 0.0002720528]\n",
      "Gen Loss: 3.69584 Disc Loss: 0.513773 Q Losses: [0.036096923, 0.00073529652]\n",
      "Gen Loss: 5.0147 Disc Loss: 0.647993 Q Losses: [0.042658255, 0.0021304304]\n",
      "Gen Loss: 1.51725 Disc Loss: 0.794551 Q Losses: [0.029307453, 0.0016676006]\n",
      "Saved Model on  37000\n",
      "Gen Loss: 2.41866 Disc Loss: 0.472529 Q Losses: [0.02377945, 0.055654094]\n",
      "Gen Loss: 2.88156 Disc Loss: 0.481729 Q Losses: [0.030776523, 0.0038977063]\n",
      "Gen Loss: 3.34991 Disc Loss: 0.625325 Q Losses: [0.02752234, 0.0054938649]\n",
      "Gen Loss: 5.19571 Disc Loss: 0.892018 Q Losses: [0.046546094, 0.012438374]\n",
      "Gen Loss: 4.11328 Disc Loss: 0.712718 Q Losses: [0.033971008, 0.0016290685]\n",
      "Gen Loss: 1.64751 Disc Loss: 0.45016 Q Losses: [0.023687709, 0.0023748004]\n",
      "Gen Loss: 3.55801 Disc Loss: 0.535825 Q Losses: [0.031205423, 0.00054589263]\n",
      "Gen Loss: 2.59918 Disc Loss: 0.361474 Q Losses: [0.031040145, 0.0020060539]\n",
      "Gen Loss: 2.56731 Disc Loss: 0.588412 Q Losses: [0.034114026, 0.0044277855]\n",
      "Gen Loss: 3.38808 Disc Loss: 0.831454 Q Losses: [0.050947305, 0.025920153]\n",
      "Saved Model on  38000\n",
      "Gen Loss: 3.11936 Disc Loss: 0.344411 Q Losses: [0.032711267, 0.020572133]\n",
      "Gen Loss: 6.95319 Disc Loss: 0.933906 Q Losses: [0.028093603, 0.00040139697]\n",
      "Gen Loss: 2.4718 Disc Loss: 0.466621 Q Losses: [0.030172184, 0.0047161747]\n",
      "Gen Loss: 1.49797 Disc Loss: 0.678706 Q Losses: [0.050957117, 0.092439778]\n",
      "Gen Loss: 1.94338 Disc Loss: 0.474503 Q Losses: [0.041717447, 0.014709462]\n",
      "Gen Loss: 2.13587 Disc Loss: 0.633959 Q Losses: [0.030746605, 0.0088335909]\n",
      "Gen Loss: 1.82664 Disc Loss: 0.563392 Q Losses: [0.048305605, 0.00054484326]\n",
      "Gen Loss: 1.29445 Disc Loss: 0.598664 Q Losses: [0.03577181, 0.0016113656]\n",
      "Gen Loss: 2.79694 Disc Loss: 0.664177 Q Losses: [0.05445502, 0.0029321732]\n",
      "Gen Loss: 2.45197 Disc Loss: 0.305232 Q Losses: [0.052494504, 0.036404025]\n",
      "Saved Model on  39000\n",
      "Gen Loss: 1.88694 Disc Loss: 0.435583 Q Losses: [0.033734009, 0.023950251]\n",
      "Gen Loss: 2.88165 Disc Loss: 0.333097 Q Losses: [0.034317244, 0.0012178386]\n",
      "Gen Loss: 1.99384 Disc Loss: 0.468543 Q Losses: [0.043680444, 0.0066285804]\n",
      "Gen Loss: 3.43843 Disc Loss: 0.477038 Q Losses: [0.035043895, 0.0037015323]\n",
      "Gen Loss: 2.12787 Disc Loss: 0.431206 Q Losses: [0.034350574, 0.0032109993]\n",
      "Gen Loss: 1.80622 Disc Loss: 0.304022 Q Losses: [0.038507644, 0.10292596]\n",
      "Gen Loss: 4.29211 Disc Loss: 0.33204 Q Losses: [0.035547774, 0.0024744722]\n",
      "Gen Loss: -0.652001 Disc Loss: 1.32179 Q Losses: [0.035532795, 0.00092056923]\n",
      "Gen Loss: -1.18831 Disc Loss: 1.20305 Q Losses: [0.027952466, 0.0055858577]\n",
      "Gen Loss: 2.48844 Disc Loss: 0.811253 Q Losses: [0.026616156, 0.013307899]\n",
      "Saved Model on  40000\n",
      "Gen Loss: 2.75885 Disc Loss: 0.399911 Q Losses: [0.043089345, 0.016754085]\n",
      "Gen Loss: 2.19858 Disc Loss: 0.421715 Q Losses: [0.031330083, 0.0017192123]\n",
      "Gen Loss: 3.66302 Disc Loss: 0.585213 Q Losses: [0.05526299, 0.0020346497]\n",
      "Gen Loss: 4.43477 Disc Loss: 0.496407 Q Losses: [0.031737052, 0.0030993535]\n",
      "Gen Loss: -0.347329 Disc Loss: 1.4415 Q Losses: [0.032966889, 0.0064121825]\n",
      "Gen Loss: 2.66285 Disc Loss: 0.347749 Q Losses: [0.0301778, 0.00079342682]\n",
      "Gen Loss: 2.07561 Disc Loss: 0.58744 Q Losses: [0.030135963, 0.0061634495]\n",
      "Gen Loss: 1.9189 Disc Loss: 0.438367 Q Losses: [0.037008956, 0.0013150639]\n",
      "Gen Loss: 2.84337 Disc Loss: 0.390435 Q Losses: [0.035831928, 0.0020407569]\n",
      "Gen Loss: 3.06415 Disc Loss: 0.374851 Q Losses: [0.029053045, 0.012611747]\n",
      "Saved Model on  41000\n",
      "Gen Loss: 2.47135 Disc Loss: 0.655455 Q Losses: [0.032151818, 0.0019912589]\n",
      "Gen Loss: 2.23427 Disc Loss: 0.998546 Q Losses: [0.029645804, 0.019183256]\n",
      "Gen Loss: 3.17196 Disc Loss: 0.541029 Q Losses: [0.036118202, 0.001417578]\n",
      "Gen Loss: 3.48686 Disc Loss: 0.331548 Q Losses: [0.0321001, 0.0090237157]\n",
      "Gen Loss: 3.50515 Disc Loss: 0.378984 Q Losses: [0.036497205, 0.00097169081]\n",
      "Gen Loss: 2.56093 Disc Loss: 0.242725 Q Losses: [0.028263617, 0.00021310573]\n",
      "Gen Loss: 3.45044 Disc Loss: 0.440395 Q Losses: [0.03632272, 0.0058757104]\n",
      "Gen Loss: 2.36019 Disc Loss: 0.433432 Q Losses: [0.042452037, 0.0094893426]\n",
      "Gen Loss: 3.97993 Disc Loss: 0.391962 Q Losses: [0.043631457, 0.040345289]\n",
      "Gen Loss: 0.129457 Disc Loss: 0.644041 Q Losses: [0.033414625, 0.00047174672]\n",
      "Saved Model on  42000\n",
      "Gen Loss: 5.36143 Disc Loss: 0.947484 Q Losses: [0.040027753, 0.025003692]\n",
      "Gen Loss: 1.08859 Disc Loss: 0.545747 Q Losses: [0.031884111, 0.0080465116]\n",
      "Gen Loss: 0.871518 Disc Loss: 1.34792 Q Losses: [0.021523453, 0.0048202565]\n",
      "Gen Loss: 2.8307 Disc Loss: 0.431972 Q Losses: [0.040334217, 0.0063756439]\n",
      "Gen Loss: -1.52348 Disc Loss: 1.73499 Q Losses: [0.036205754, 0.022111828]\n",
      "Gen Loss: 3.57626 Disc Loss: 0.380149 Q Losses: [0.035893522, 0.0018657648]\n",
      "Gen Loss: 2.03932 Disc Loss: 0.465623 Q Losses: [0.044924743, 0.00071907532]\n",
      "Gen Loss: 2.48949 Disc Loss: 1.0453 Q Losses: [0.037388079, 0.0018910845]\n",
      "Gen Loss: 2.80507 Disc Loss: 0.644951 Q Losses: [0.028628016, 0.00078545942]\n",
      "Gen Loss: 4.10462 Disc Loss: 0.167962 Q Losses: [0.021964129, 0.00083439489]\n",
      "Saved Model on  43000\n",
      "Gen Loss: 4.53095 Disc Loss: 0.640203 Q Losses: [0.041540626, 0.0017156615]\n",
      "Gen Loss: 5.03684 Disc Loss: 0.663107 Q Losses: [0.027704721, 0.0016730137]\n",
      "Gen Loss: 2.13865 Disc Loss: 0.482404 Q Losses: [0.040456951, 0.022558417]\n",
      "Gen Loss: 3.37455 Disc Loss: 0.34046 Q Losses: [0.047608212, 0.0013539525]\n",
      "Gen Loss: 5.15039 Disc Loss: 0.692055 Q Losses: [0.042362206, 0.0014901959]\n",
      "Gen Loss: 3.0903 Disc Loss: 0.43066 Q Losses: [0.034274697, 0.0015285678]\n",
      "Gen Loss: 5.88076 Disc Loss: 1.96009 Q Losses: [0.033550166, 0.055347294]\n",
      "Gen Loss: 4.09467 Disc Loss: 0.503464 Q Losses: [0.04630705, 0.023969006]\n",
      "Gen Loss: 2.89148 Disc Loss: 0.508077 Q Losses: [0.030480323, 0.044602212]\n",
      "Gen Loss: 2.7136 Disc Loss: 0.540339 Q Losses: [0.029660471, 0.001756847]\n",
      "Saved Model on  44000\n",
      "Gen Loss: 1.4959 Disc Loss: 2.4929 Q Losses: [0.035555609, 0.0027818843]\n",
      "Gen Loss: 2.84647 Disc Loss: 0.542947 Q Losses: [0.043081179, 0.030129453]\n",
      "Gen Loss: 1.18422 Disc Loss: 1.05657 Q Losses: [0.029219462, 0.0015830277]\n",
      "Gen Loss: 4.3521 Disc Loss: 0.866742 Q Losses: [0.035942949, 0.060378894]\n",
      "Gen Loss: 3.84253 Disc Loss: 0.540528 Q Losses: [0.0294929, 0.00090454507]\n",
      "Gen Loss: 3.19777 Disc Loss: 0.290565 Q Losses: [0.024806961, 0.0015726886]\n",
      "Gen Loss: 2.93438 Disc Loss: 0.440314 Q Losses: [0.03271858, 0.0015728166]\n",
      "Gen Loss: 2.74467 Disc Loss: 0.365673 Q Losses: [0.02592152, 0.00086065341]\n",
      "Gen Loss: 3.93833 Disc Loss: 0.433067 Q Losses: [0.025767948, 0.00079335034]\n",
      "Gen Loss: 2.73595 Disc Loss: 0.610928 Q Losses: [0.037394382, 0.014169482]\n",
      "Saved Model on  45000\n",
      "Gen Loss: 2.89201 Disc Loss: 0.610844 Q Losses: [0.042964198, 0.0052000894]\n",
      "Gen Loss: 4.30216 Disc Loss: 0.49439 Q Losses: [0.02632967, 0.04151893]\n",
      "Gen Loss: 2.9737 Disc Loss: 0.309267 Q Losses: [0.042709209, 0.010672901]\n",
      "Gen Loss: 4.46489 Disc Loss: 0.614576 Q Losses: [0.025119681, 0.0012954785]\n",
      "Gen Loss: 4.47321 Disc Loss: 0.604939 Q Losses: [0.027799085, 0.01381861]\n",
      "Gen Loss: 4.30368 Disc Loss: 0.68798 Q Losses: [0.042065464, 0.02379409]\n",
      "Gen Loss: 1.03459 Disc Loss: 0.766155 Q Losses: [0.045141041, 0.0039992682]\n",
      "Gen Loss: 3.99165 Disc Loss: 0.949972 Q Losses: [0.035431944, 0.040958256]\n",
      "Gen Loss: 4.72899 Disc Loss: 0.609528 Q Losses: [0.038788274, 0.0048126234]\n",
      "Gen Loss: 2.48275 Disc Loss: 0.551369 Q Losses: [0.032057598, 0.0056103682]\n",
      "Saved Model on  46000\n",
      "Gen Loss: 2.43494 Disc Loss: 0.367793 Q Losses: [0.029622056, 0.011169236]\n",
      "Gen Loss: 3.90293 Disc Loss: 0.4766 Q Losses: [0.044915337, 0.00036820155]\n",
      "Gen Loss: 2.82991 Disc Loss: 0.338572 Q Losses: [0.0331879, 0.01678553]\n",
      "Gen Loss: 4.38891 Disc Loss: 0.46213 Q Losses: [0.030563563, 0.00027672353]\n",
      "Gen Loss: 5.18372 Disc Loss: 0.460483 Q Losses: [0.034759887, 0.011523517]\n",
      "Gen Loss: 3.6562 Disc Loss: 0.414129 Q Losses: [0.029924393, 0.027649153]\n",
      "Gen Loss: 5.06523 Disc Loss: 0.596572 Q Losses: [0.04870227, 0.015887767]\n",
      "Gen Loss: 4.51472 Disc Loss: 0.680333 Q Losses: [0.039028682, 0.0056675677]\n",
      "Gen Loss: 1.87197 Disc Loss: 0.621587 Q Losses: [0.036691047, 0.0030961719]\n",
      "Gen Loss: 2.09397 Disc Loss: 0.697742 Q Losses: [0.033871055, 0.0080769733]\n",
      "Saved Model on  47000\n",
      "Gen Loss: 2.14373 Disc Loss: 0.462285 Q Losses: [0.028193904, 0.064772718]\n",
      "Gen Loss: 3.67938 Disc Loss: 0.437033 Q Losses: [0.040368944, 0.001225912]\n",
      "Gen Loss: 3.11872 Disc Loss: 0.456072 Q Losses: [0.032962389, 0.0019303053]\n",
      "Gen Loss: 3.48058 Disc Loss: 0.420239 Q Losses: [0.051962819, 0.016614858]\n",
      "Gen Loss: 3.51189 Disc Loss: 0.285326 Q Losses: [0.033094265, 0.0060817092]\n",
      "Gen Loss: 3.9307 Disc Loss: 0.374027 Q Losses: [0.030475238, 0.0094205942]\n",
      "Gen Loss: 0.745641 Disc Loss: 1.02771 Q Losses: [0.033547081, 0.0084916325]\n",
      "Gen Loss: 1.57391 Disc Loss: 0.446272 Q Losses: [0.029619938, 0.0013563512]\n",
      "Gen Loss: 1.84903 Disc Loss: 0.417262 Q Losses: [0.033754092, 0.017301515]\n",
      "Gen Loss: 3.70434 Disc Loss: 0.235568 Q Losses: [0.041484259, 0.0039229244]\n",
      "Saved Model on  48000\n",
      "Gen Loss: 4.43936 Disc Loss: 0.501862 Q Losses: [0.025189579, 0.012695462]\n",
      "Gen Loss: 3.16407 Disc Loss: 0.369315 Q Losses: [0.034365866, 0.057043459]\n",
      "Gen Loss: 0.77321 Disc Loss: 0.59884 Q Losses: [0.028269671, 0.0010604165]\n",
      "Gen Loss: 1.48342 Disc Loss: 0.576709 Q Losses: [0.03458019, 0.00096914335]\n",
      "Gen Loss: 2.70589 Disc Loss: 0.359566 Q Losses: [0.031490568, 0.026546728]\n",
      "Gen Loss: 2.64174 Disc Loss: 0.566771 Q Losses: [0.032060049, 0.0037565108]\n",
      "Gen Loss: 3.92331 Disc Loss: 0.422432 Q Losses: [0.036146697, 0.0019547648]\n",
      "Gen Loss: 3.50751 Disc Loss: 0.480911 Q Losses: [0.029082742, 0.00056917337]\n",
      "Gen Loss: 4.45306 Disc Loss: 0.495776 Q Losses: [0.025891703, 0.0011814291]\n",
      "Gen Loss: 3.84881 Disc Loss: 0.360454 Q Losses: [0.029567758, 0.0030355421]\n",
      "Saved Model on  49000\n",
      "Gen Loss: 2.92389 Disc Loss: 0.355488 Q Losses: [0.028347321, 0.031024538]\n",
      "Gen Loss: 4.16027 Disc Loss: 0.627058 Q Losses: [0.045346014, 0.019082587]\n",
      "Gen Loss: 1.79262 Disc Loss: 0.37926 Q Losses: [0.029642396, 0.002615626]\n",
      "Gen Loss: 0.671078 Disc Loss: 0.699661 Q Losses: [0.031869605, 0.016754294]\n",
      "Gen Loss: 4.48043 Disc Loss: 0.532251 Q Losses: [0.030143529, 0.012913525]\n",
      "Gen Loss: 1.74684 Disc Loss: 0.371848 Q Losses: [0.029789971, 0.047555562]\n",
      "Gen Loss: 6.21905 Disc Loss: 0.801376 Q Losses: [0.031953365, 0.010184305]\n",
      "Gen Loss: 4.64464 Disc Loss: 0.744903 Q Losses: [0.041475803, 0.0010638046]\n",
      "Gen Loss: 3.19395 Disc Loss: 0.244446 Q Losses: [0.044321924, 0.0040159128]\n",
      "Gen Loss: 4.91949 Disc Loss: 0.253706 Q Losses: [0.037583385, 0.013952067]\n",
      "Saved Model on  50000\n",
      "Gen Loss: 0.847886 Disc Loss: 0.868768 Q Losses: [0.033156618, 0.041324172]\n",
      "Gen Loss: 1.67158 Disc Loss: 0.707767 Q Losses: [0.045701742, 0.010681767]\n",
      "Gen Loss: 4.25616 Disc Loss: 0.552602 Q Losses: [0.033812959, 0.011435967]\n",
      "Gen Loss: 4.2064 Disc Loss: 0.337946 Q Losses: [0.027466424, 0.053386346]\n",
      "Gen Loss: 1.95535 Disc Loss: 0.652885 Q Losses: [0.037142694, 0.02713746]\n",
      "Gen Loss: 2.63794 Disc Loss: 0.377152 Q Losses: [0.031425074, 0.0033158218]\n",
      "Gen Loss: 3.19637 Disc Loss: 0.396352 Q Losses: [0.026344303, 0.011133031]\n",
      "Gen Loss: 4.41578 Disc Loss: 0.625137 Q Losses: [0.033305861, 0.00095107779]\n",
      "Gen Loss: 1.30091 Disc Loss: 0.627127 Q Losses: [0.038163662, 0.036851682]\n",
      "Gen Loss: 2.83035 Disc Loss: 0.590556 Q Losses: [0.025920946, 0.00061232049]\n",
      "Saved Model on  51000\n",
      "Gen Loss: 4.41113 Disc Loss: 0.307833 Q Losses: [0.03490635, 0.00094157225]\n",
      "Gen Loss: 2.82704 Disc Loss: 0.229295 Q Losses: [0.033365753, 0.0045587546]\n",
      "Gen Loss: 3.92814 Disc Loss: 0.328267 Q Losses: [0.032646637, 0.014963187]\n",
      "Gen Loss: 6.09458 Disc Loss: 0.664241 Q Losses: [0.035611205, 0.0037682822]\n",
      "Gen Loss: 5.25587 Disc Loss: 0.424447 Q Losses: [0.034594286, 0.076526754]\n",
      "Gen Loss: 4.48596 Disc Loss: 0.393076 Q Losses: [0.0302174, 0.00056756072]\n",
      "Gen Loss: 4.24756 Disc Loss: 0.287639 Q Losses: [0.036531687, 0.001970192]\n",
      "Gen Loss: 3.07712 Disc Loss: 0.537607 Q Losses: [0.041336086, 0.0027196459]\n",
      "Gen Loss: 1.77184 Disc Loss: 0.480591 Q Losses: [0.032778554, 0.03271015]\n",
      "Gen Loss: 3.65876 Disc Loss: 0.346496 Q Losses: [0.0288954, 0.0018221098]\n",
      "Saved Model on  52000\n",
      "Gen Loss: 2.98512 Disc Loss: 0.23455 Q Losses: [0.029174063, 0.00084348302]\n",
      "Gen Loss: 3.32166 Disc Loss: 0.425153 Q Losses: [0.036244959, 0.012907983]\n",
      "Gen Loss: 4.27948 Disc Loss: 0.304117 Q Losses: [0.027722606, 0.056168858]\n",
      "Gen Loss: 2.91013 Disc Loss: 0.410384 Q Losses: [0.045163516, 0.0043051927]\n",
      "Gen Loss: 5.47188 Disc Loss: 1.00509 Q Losses: [0.041604787, 0.0066190888]\n",
      "Gen Loss: 3.46799 Disc Loss: 0.370767 Q Losses: [0.039254591, 0.00079058058]\n",
      "Gen Loss: 3.28003 Disc Loss: 0.883408 Q Losses: [0.026346486, 0.0059582884]\n",
      "Gen Loss: 1.35516 Disc Loss: 0.825109 Q Losses: [0.055887107, 0.00049346872]\n",
      "Gen Loss: 4.73036 Disc Loss: 0.14176 Q Losses: [0.051835068, 0.0013476158]\n",
      "Gen Loss: 0.36966 Disc Loss: 0.68969 Q Losses: [0.033201132, 0.046689913]\n",
      "Saved Model on  53000\n",
      "Gen Loss: 2.98834 Disc Loss: 0.513152 Q Losses: [0.043814197, 0.078716323]\n",
      "Gen Loss: 4.67868 Disc Loss: 0.316427 Q Losses: [0.031768881, 0.058565542]\n",
      "Gen Loss: 1.41607 Disc Loss: 0.654782 Q Losses: [0.032482117, 0.058336008]\n",
      "Gen Loss: 3.24102 Disc Loss: 0.716633 Q Losses: [0.027165102, 0.031030975]\n",
      "Gen Loss: 5.13664 Disc Loss: 0.688284 Q Losses: [0.035552923, 0.0018623304]\n",
      "Gen Loss: 3.7469 Disc Loss: 0.194438 Q Losses: [0.027613487, 0.0023616627]\n",
      "Gen Loss: 4.8848 Disc Loss: 0.559889 Q Losses: [0.034900688, 0.0069775931]\n",
      "Gen Loss: 4.61614 Disc Loss: 0.336607 Q Losses: [0.032178503, 0.0013618127]\n",
      "Gen Loss: 4.24051 Disc Loss: 0.578093 Q Losses: [0.03522066, 0.0030388627]\n",
      "Gen Loss: 5.86276 Disc Loss: 0.74422 Q Losses: [0.032276265, 0.010359876]\n",
      "Saved Model on  54000\n",
      "Gen Loss: 1.54732 Disc Loss: 0.982512 Q Losses: [0.033691898, 0.0010231194]\n",
      "Gen Loss: 4.49235 Disc Loss: 0.386526 Q Losses: [0.031781998, 0.0020591905]\n",
      "Gen Loss: 3.6204 Disc Loss: 0.5849 Q Losses: [0.025385318, 0.0027853132]\n",
      "Gen Loss: 3.43135 Disc Loss: 0.481871 Q Losses: [0.03098405, 0.010117717]\n",
      "Gen Loss: 3.32342 Disc Loss: 0.343072 Q Losses: [0.032347627, 0.00014740304]\n",
      "Gen Loss: 4.45434 Disc Loss: 0.219872 Q Losses: [0.033335216, 0.00025179092]\n",
      "Gen Loss: 4.93092 Disc Loss: 1.14132 Q Losses: [0.042980134, 0.0054074759]\n",
      "Gen Loss: 3.36333 Disc Loss: 0.554397 Q Losses: [0.034152925, 0.012521147]\n",
      "Gen Loss: 3.90666 Disc Loss: 0.463526 Q Losses: [0.029405456, 0.00018128716]\n",
      "Gen Loss: 3.68815 Disc Loss: 0.364528 Q Losses: [0.039264161, 0.0064035454]\n",
      "Saved Model on  55000\n",
      "Gen Loss: 3.84379 Disc Loss: 0.216883 Q Losses: [0.031916037, 0.00022311245]\n",
      "Gen Loss: 3.22921 Disc Loss: 0.312455 Q Losses: [0.032967035, 0.04556885]\n",
      "Gen Loss: 4.39729 Disc Loss: 0.33143 Q Losses: [0.033183649, 0.020479053]\n",
      "Gen Loss: 2.50905 Disc Loss: 0.402832 Q Losses: [0.028140035, 0.047273271]\n",
      "Gen Loss: 3.11031 Disc Loss: 0.381285 Q Losses: [0.026095461, 0.0059912056]\n",
      "Gen Loss: 3.53528 Disc Loss: 0.215566 Q Losses: [0.038758337, 0.0011492133]\n",
      "Gen Loss: 3.75607 Disc Loss: 0.348612 Q Losses: [0.031867616, 0.022914553]\n",
      "Gen Loss: 2.99069 Disc Loss: 0.274156 Q Losses: [0.027347362, 0.00025685588]\n",
      "Gen Loss: 3.69695 Disc Loss: 0.260745 Q Losses: [0.033319578, 0.012019703]\n",
      "Gen Loss: 3.31137 Disc Loss: 0.430218 Q Losses: [0.035152562, 0.019405734]\n",
      "Saved Model on  56000\n",
      "Gen Loss: 4.35754 Disc Loss: 0.216219 Q Losses: [0.033227682, 0.00057124085]\n",
      "Gen Loss: -0.730913 Disc Loss: 0.871561 Q Losses: [0.030371521, 0.0060172975]\n",
      "Gen Loss: 6.60823 Disc Loss: 1.87787 Q Losses: [0.034109198, 0.0018097543]\n",
      "Gen Loss: 4.21887 Disc Loss: 0.283916 Q Losses: [0.027490009, 0.0030775503]\n",
      "Gen Loss: 7.41997 Disc Loss: 1.33547 Q Losses: [0.034173623, 0.028328411]\n",
      "Gen Loss: 1.20196 Disc Loss: 0.371576 Q Losses: [0.040301502, 0.001018147]\n",
      "Gen Loss: 4.28406 Disc Loss: 0.247021 Q Losses: [0.032039866, 0.0017661838]\n",
      "Gen Loss: 4.04683 Disc Loss: 0.293616 Q Losses: [0.03453153, 0.0058973185]\n",
      "Gen Loss: 3.98898 Disc Loss: 0.272311 Q Losses: [0.0415162, 0.0045111412]\n",
      "Gen Loss: 5.32676 Disc Loss: 0.411885 Q Losses: [0.031613849, 0.0012246753]\n",
      "Saved Model on  57000\n",
      "Gen Loss: 2.25199 Disc Loss: 0.69737 Q Losses: [0.028994502, 0.0043405709]\n",
      "Gen Loss: 5.40818 Disc Loss: 0.569116 Q Losses: [0.038814828, 0.00014453201]\n",
      "Gen Loss: 3.91629 Disc Loss: 0.481968 Q Losses: [0.033466186, 0.003114593]\n",
      "Gen Loss: 3.45036 Disc Loss: 0.325802 Q Losses: [0.040614307, 0.012797475]\n",
      "Gen Loss: 3.47718 Disc Loss: 0.267403 Q Losses: [0.024947966, 0.0010963823]\n",
      "Gen Loss: 3.71962 Disc Loss: 0.287235 Q Losses: [0.033544801, 0.0012345053]\n",
      "Gen Loss: 4.32509 Disc Loss: 0.327798 Q Losses: [0.032474414, 0.0052042897]\n",
      "Gen Loss: 2.77689 Disc Loss: 0.40299 Q Losses: [0.032838549, 0.0095453383]\n",
      "Gen Loss: 2.81711 Disc Loss: 0.246631 Q Losses: [0.055781037, 0.0049723862]\n",
      "Gen Loss: 4.04447 Disc Loss: 0.340282 Q Losses: [0.02712401, 0.00042922897]\n",
      "Saved Model on  58000\n",
      "Gen Loss: 2.86618 Disc Loss: 0.325161 Q Losses: [0.025730316, 0.021907825]\n",
      "Gen Loss: 3.20277 Disc Loss: 0.313399 Q Losses: [0.029223867, 0.0026862228]\n",
      "Gen Loss: 4.77915 Disc Loss: 0.745559 Q Losses: [0.024642181, 0.0020592667]\n",
      "Gen Loss: 3.81969 Disc Loss: 0.465846 Q Losses: [0.04430946, 0.0027696087]\n",
      "Gen Loss: 4.87623 Disc Loss: 0.616786 Q Losses: [0.028955275, 0.0036028558]\n",
      "Gen Loss: 3.37098 Disc Loss: 0.228503 Q Losses: [0.029150017, 0.00081235898]\n",
      "Gen Loss: 5.44809 Disc Loss: 1.09617 Q Losses: [0.035493456, 0.057889678]\n",
      "Gen Loss: 4.42858 Disc Loss: 0.493331 Q Losses: [0.027948424, 0.0011093956]\n",
      "Gen Loss: 3.35304 Disc Loss: 0.351044 Q Losses: [0.033684663, 0.011953744]\n",
      "Gen Loss: 3.77352 Disc Loss: 0.478926 Q Losses: [0.02776421, 0.0014080508]\n",
      "Saved Model on  59000\n",
      "Gen Loss: 3.20597 Disc Loss: 0.833112 Q Losses: [0.062994316, 0.010773418]\n",
      "Gen Loss: 4.73249 Disc Loss: 1.35089 Q Losses: [0.049315274, 0.13247788]\n",
      "Gen Loss: 3.61146 Disc Loss: 0.372259 Q Losses: [0.031884603, 0.0021625396]\n",
      "Gen Loss: 3.7274 Disc Loss: 0.353483 Q Losses: [0.029614184, 0.0094690006]\n",
      "Gen Loss: 2.47496 Disc Loss: 0.372705 Q Losses: [0.02750499, 0.0052161501]\n",
      "Gen Loss: 4.92129 Disc Loss: 0.444914 Q Losses: [0.032359645, 0.016022302]\n",
      "Gen Loss: 2.17598 Disc Loss: 0.454306 Q Losses: [0.03036011, 0.00046788366]\n",
      "Gen Loss: 3.94168 Disc Loss: 0.254692 Q Losses: [0.032274731, 0.0027911123]\n",
      "Gen Loss: 4.36067 Disc Loss: 0.251235 Q Losses: [0.054938763, 0.0015207845]\n",
      "Gen Loss: 4.12719 Disc Loss: 0.275076 Q Losses: [0.032564215, 0.17373458]\n",
      "Saved Model on  60000\n",
      "Gen Loss: 4.89738 Disc Loss: 0.288005 Q Losses: [0.026966598, 0.0011058137]\n",
      "Gen Loss: 3.76265 Disc Loss: 0.319602 Q Losses: [0.029176299, 0.0016243581]\n",
      "Gen Loss: 4.10807 Disc Loss: 0.350875 Q Losses: [0.03893714, 0.00097099942]\n",
      "Gen Loss: 2.96404 Disc Loss: 0.46092 Q Losses: [0.031239055, 0.00084025215]\n",
      "Gen Loss: 4.2521 Disc Loss: 0.308 Q Losses: [0.030819867, 0.0014073257]\n",
      "Gen Loss: 4.01066 Disc Loss: 0.27327 Q Losses: [0.03372322, 0.098432548]\n",
      "Gen Loss: 4.30394 Disc Loss: 0.363844 Q Losses: [0.023212224, 0.00050070579]\n",
      "Gen Loss: 3.73017 Disc Loss: 0.380893 Q Losses: [0.039429449, 0.0015907367]\n",
      "Gen Loss: 4.96192 Disc Loss: 0.719228 Q Losses: [0.023433102, 8.5295862e-05]\n",
      "Gen Loss: 4.88982 Disc Loss: 0.159056 Q Losses: [0.031153575, 0.00099488522]\n",
      "Saved Model on  61000\n",
      "Gen Loss: 4.37114 Disc Loss: 0.197182 Q Losses: [0.034384973, 0.002562508]\n",
      "Gen Loss: 2.51361 Disc Loss: 0.263958 Q Losses: [0.02415354, 0.00047365081]\n",
      "Gen Loss: 2.05504 Disc Loss: 1.01043 Q Losses: [0.025981465, 0.0074822418]\n",
      "Gen Loss: 3.73697 Disc Loss: 0.229922 Q Losses: [0.029656645, 0.012803163]\n",
      "Gen Loss: 4.22147 Disc Loss: 0.261477 Q Losses: [0.04022266, 0.0040947655]\n",
      "Gen Loss: 3.04043 Disc Loss: 0.514007 Q Losses: [0.027728625, 0.029994126]\n",
      "Gen Loss: 1.52862 Disc Loss: 0.597914 Q Losses: [0.030521328, 0.0035579528]\n",
      "Gen Loss: 4.90482 Disc Loss: 0.193522 Q Losses: [0.028508388, 0.034641217]\n",
      "Gen Loss: 3.21379 Disc Loss: 0.827008 Q Losses: [0.027340258, 0.0020392698]\n",
      "Gen Loss: 4.30882 Disc Loss: 0.356463 Q Losses: [0.030275228, 0.071624421]\n",
      "Saved Model on  62000\n",
      "Gen Loss: 3.0535 Disc Loss: 0.315303 Q Losses: [0.041889351, 0.07651291]\n",
      "Gen Loss: 3.58454 Disc Loss: 0.694212 Q Losses: [0.031254802, 0.0020236582]\n",
      "Gen Loss: 4.86601 Disc Loss: 0.485885 Q Losses: [0.034495294, 0.00036031508]\n",
      "Gen Loss: 2.59001 Disc Loss: 0.318226 Q Losses: [0.03332188, 0.0047791824]\n",
      "Gen Loss: 6.22806 Disc Loss: 0.736996 Q Losses: [0.02684929, 0.0027158735]\n",
      "Gen Loss: 3.57569 Disc Loss: 0.327112 Q Losses: [0.033912078, 0.0058830888]\n",
      "Gen Loss: 2.74881 Disc Loss: 0.378942 Q Losses: [0.056732595, 0.00042780646]\n",
      "Gen Loss: 3.99562 Disc Loss: 0.333848 Q Losses: [0.027778763, 0.0011866651]\n",
      "Gen Loss: 4.88874 Disc Loss: 0.190274 Q Losses: [0.035225991, 0.0023119673]\n",
      "Gen Loss: 3.83751 Disc Loss: 0.324015 Q Losses: [0.026335765, 0.0061868378]\n",
      "Saved Model on  63000\n",
      "Gen Loss: 1.50875 Disc Loss: 0.427624 Q Losses: [0.027766842, 0.0014563637]\n",
      "Gen Loss: 4.36064 Disc Loss: 0.305946 Q Losses: [0.026555805, 0.00028440083]\n",
      "Gen Loss: 3.23571 Disc Loss: 0.350376 Q Losses: [0.035512969, 0.006592718]\n",
      "Gen Loss: 1.44105 Disc Loss: 0.59993 Q Losses: [0.039461311, 0.039988346]\n",
      "Gen Loss: 3.83587 Disc Loss: 0.235019 Q Losses: [0.031960398, 0.003147183]\n",
      "Gen Loss: 2.89485 Disc Loss: 0.582652 Q Losses: [0.022019293, 0.004833241]\n",
      "Gen Loss: 4.20245 Disc Loss: 0.300261 Q Losses: [0.033891369, 0.037570827]\n",
      "Gen Loss: 4.27926 Disc Loss: 0.169646 Q Losses: [0.026726026, 0.0021343143]\n",
      "Gen Loss: 5.20911 Disc Loss: 0.538839 Q Losses: [0.029995617, 0.014190025]\n",
      "Gen Loss: 4.00196 Disc Loss: 0.264437 Q Losses: [0.053343307, 0.00096386427]\n",
      "Saved Model on  64000\n",
      "Gen Loss: 4.37363 Disc Loss: 0.368212 Q Losses: [0.030417647, 0.0081524746]\n",
      "Gen Loss: 4.36877 Disc Loss: 0.299196 Q Losses: [0.035408214, 0.0020001184]\n",
      "Gen Loss: 4.14622 Disc Loss: 0.422169 Q Losses: [0.040930018, 0.01203258]\n",
      "Gen Loss: 1.43667 Disc Loss: 0.638881 Q Losses: [0.038149718, 0.002362492]\n",
      "Gen Loss: 2.64133 Disc Loss: 0.364462 Q Losses: [0.039857317, 0.010454309]\n",
      "Gen Loss: 3.735 Disc Loss: 0.397321 Q Losses: [0.039469082, 0.00086894084]\n",
      "Gen Loss: 4.90772 Disc Loss: 0.490123 Q Losses: [0.047221906, 0.04120218]\n",
      "Gen Loss: 3.12232 Disc Loss: 0.261546 Q Losses: [0.030856457, 0.023544379]\n",
      "Gen Loss: 4.36462 Disc Loss: 0.425309 Q Losses: [0.031443194, 0.0027466414]\n",
      "Gen Loss: 3.56412 Disc Loss: 0.268891 Q Losses: [0.026716743, 0.0015402256]\n",
      "Saved Model on  65000\n",
      "Gen Loss: 3.16867 Disc Loss: 0.523493 Q Losses: [0.03948804, 0.0036919531]\n",
      "Gen Loss: 3.85126 Disc Loss: 0.400757 Q Losses: [0.039558679, 0.0065074684]\n",
      "Gen Loss: 3.79201 Disc Loss: 0.294978 Q Losses: [0.032783929, 0.0011115568]\n",
      "Gen Loss: 3.05018 Disc Loss: 0.290476 Q Losses: [0.035586584, 0.0011959882]\n",
      "Gen Loss: 2.45803 Disc Loss: 0.320603 Q Losses: [0.021272045, 0.003557452]\n",
      "Gen Loss: 5.72404 Disc Loss: 1.0318 Q Losses: [0.036189362, 0.0088531515]\n",
      "Gen Loss: 4.62347 Disc Loss: 0.350958 Q Losses: [0.033869002, 0.0033237296]\n",
      "Gen Loss: 4.77129 Disc Loss: 0.279253 Q Losses: [0.033276349, 0.0020755774]\n",
      "Gen Loss: 2.40116 Disc Loss: 0.256151 Q Losses: [0.025218606, 0.11935433]\n",
      "Gen Loss: 2.70707 Disc Loss: 0.374943 Q Losses: [0.028115131, 0.0018393579]\n",
      "Saved Model on  66000\n",
      "Gen Loss: 3.10337 Disc Loss: 0.269251 Q Losses: [0.032367092, 0.0036461358]\n",
      "Gen Loss: 3.10786 Disc Loss: 0.344461 Q Losses: [0.034323882, 8.7806882e-05]\n",
      "Gen Loss: 1.11478 Disc Loss: 0.723091 Q Losses: [0.031337935, 0.016409745]\n",
      "Gen Loss: 4.10983 Disc Loss: 0.690396 Q Losses: [0.03520453, 0.00036357128]\n",
      "Gen Loss: 2.74886 Disc Loss: 1.18654 Q Losses: [0.029960468, 0.0036800667]\n",
      "Gen Loss: 1.92121 Disc Loss: 0.450427 Q Losses: [0.031025739, 0.0068605524]\n",
      "Gen Loss: 4.59002 Disc Loss: 0.507883 Q Losses: [0.032363065, 0.00099687569]\n",
      "Gen Loss: 3.34668 Disc Loss: 0.267095 Q Losses: [0.026852677, 0.011088068]\n",
      "Gen Loss: 3.69763 Disc Loss: 0.26005 Q Losses: [0.025627537, 0.0026475494]\n",
      "Gen Loss: 4.25253 Disc Loss: 0.24749 Q Losses: [0.029281687, 0.00047021915]\n",
      "Saved Model on  67000\n",
      "Gen Loss: 4.91376 Disc Loss: 0.183141 Q Losses: [0.034205198, 0.0058412021]\n",
      "Gen Loss: 4.61194 Disc Loss: 0.345216 Q Losses: [0.030135047, 0.00024988709]\n",
      "Gen Loss: 4.63945 Disc Loss: 0.310043 Q Losses: [0.024577886, 0.0088552544]\n",
      "Gen Loss: 5.14136 Disc Loss: 0.598322 Q Losses: [0.030582029, 0.002375599]\n",
      "Gen Loss: 4.3952 Disc Loss: 0.197377 Q Losses: [0.030495752, 0.0014200464]\n",
      "Gen Loss: 4.10319 Disc Loss: 0.156143 Q Losses: [0.034533769, 0.00021024716]\n",
      "Gen Loss: 5.06659 Disc Loss: 0.660532 Q Losses: [0.043835357, 0.033927277]\n",
      "Gen Loss: 2.61776 Disc Loss: 0.458652 Q Losses: [0.038270332, 0.0057518049]\n",
      "Gen Loss: 6.69702 Disc Loss: 0.685811 Q Losses: [0.027393149, 0.00033584886]\n",
      "Gen Loss: 3.64385 Disc Loss: 0.397409 Q Losses: [0.029836999, 0.00035201258]\n",
      "Saved Model on  68000\n",
      "Gen Loss: 6.10642 Disc Loss: 0.646223 Q Losses: [0.031445865, 0.0011132986]\n",
      "Gen Loss: 5.56173 Disc Loss: 0.304591 Q Losses: [0.057698447, 0.00048399475]\n",
      "Gen Loss: 2.85321 Disc Loss: 0.5196 Q Losses: [0.034435272, 0.0010399778]\n",
      "Gen Loss: 3.93257 Disc Loss: 0.826102 Q Losses: [0.048044033, 0.00066235359]\n",
      "Gen Loss: 4.42982 Disc Loss: 0.310371 Q Losses: [0.030948309, 0.0010544056]\n",
      "Gen Loss: 2.09385 Disc Loss: 0.563815 Q Losses: [0.030401502, 0.0087963082]\n",
      "Gen Loss: 4.41545 Disc Loss: 0.372692 Q Losses: [0.02386497, 0.00057850871]\n",
      "Gen Loss: 4.2054 Disc Loss: 0.326103 Q Losses: [0.030946052, 0.00057180272]\n",
      "Gen Loss: 2.20472 Disc Loss: 0.317093 Q Losses: [0.029074423, 0.0017371939]\n",
      "Gen Loss: 3.646 Disc Loss: 0.284975 Q Losses: [0.029971316, 0.0024220743]\n",
      "Saved Model on  69000\n",
      "Gen Loss: 3.11038 Disc Loss: 0.307455 Q Losses: [0.028800551, 0.03569442]\n",
      "Gen Loss: 4.56594 Disc Loss: 0.329143 Q Losses: [0.053032659, 0.0062652007]\n",
      "Gen Loss: 1.03703 Disc Loss: 0.76405 Q Losses: [0.034531854, 0.013219063]\n",
      "Gen Loss: 4.10545 Disc Loss: 0.252009 Q Losses: [0.028961612, 0.00047040364]\n",
      "Gen Loss: 1.63105 Disc Loss: 0.380479 Q Losses: [0.032823667, 0.0016186852]\n",
      "Gen Loss: 2.52262 Disc Loss: 0.270175 Q Losses: [0.034580596, 0.0033293837]\n",
      "Gen Loss: 2.78091 Disc Loss: 0.247688 Q Losses: [0.040440295, 0.0012162365]\n",
      "Gen Loss: 3.42658 Disc Loss: 0.33679 Q Losses: [0.030847114, 0.00083138177]\n",
      "Gen Loss: 2.58406 Disc Loss: 0.448702 Q Losses: [0.035170823, 0.0020077857]\n",
      "Gen Loss: 4.91263 Disc Loss: 0.325315 Q Losses: [0.036770549, 0.0015274179]\n",
      "Saved Model on  70000\n",
      "Gen Loss: 3.5033 Disc Loss: 0.684069 Q Losses: [0.038113255, 0.063356392]\n",
      "Gen Loss: 5.52464 Disc Loss: 0.196652 Q Losses: [0.029351667, 0.00038469321]\n",
      "Gen Loss: 2.517 Disc Loss: 0.459195 Q Losses: [0.026095819, 0.008024238]\n",
      "Gen Loss: 4.33034 Disc Loss: 0.385371 Q Losses: [0.028222013, 0.0039596511]\n",
      "Gen Loss: 2.78482 Disc Loss: 0.490959 Q Losses: [0.029500002, 0.002350955]\n",
      "Gen Loss: 4.79544 Disc Loss: 0.324552 Q Losses: [0.035393015, 0.001739342]\n",
      "Gen Loss: 2.66153 Disc Loss: 0.478164 Q Losses: [0.032086182, 0.045888279]\n",
      "Gen Loss: 3.71643 Disc Loss: 0.301466 Q Losses: [0.033345848, 0.0038116425]\n",
      "Gen Loss: 4.75662 Disc Loss: 0.208597 Q Losses: [0.028207488, 0.00029594329]\n",
      "Gen Loss: 6.25891 Disc Loss: 0.511105 Q Losses: [0.02456888, 0.00054933858]\n",
      "Saved Model on  71000\n",
      "Gen Loss: 4.81823 Disc Loss: 0.936606 Q Losses: [0.031814419, 0.022693127]\n",
      "Gen Loss: 2.65136 Disc Loss: 0.555206 Q Losses: [0.028753601, 0.00026739354]\n",
      "Gen Loss: 5.16876 Disc Loss: 0.144212 Q Losses: [0.03781803, 0.0010887946]\n",
      "Gen Loss: 5.3484 Disc Loss: 0.213533 Q Losses: [0.030820735, 0.0002591082]\n",
      "Gen Loss: 5.60033 Disc Loss: 0.180488 Q Losses: [0.030910064, 0.017099127]\n",
      "Gen Loss: 5.22789 Disc Loss: 0.136764 Q Losses: [0.032072455, 0.00067123503]\n",
      "Gen Loss: 3.60294 Disc Loss: 0.704206 Q Losses: [0.034314457, 0.0026133759]\n",
      "Gen Loss: 4.27816 Disc Loss: 0.435873 Q Losses: [0.024849456, 0.00058557675]\n",
      "Gen Loss: 0.909443 Disc Loss: 0.478929 Q Losses: [0.034501083, 0.00075412414]\n",
      "Gen Loss: 5.19064 Disc Loss: 0.324004 Q Losses: [0.032273207, 0.00083968049]\n",
      "Saved Model on  72000\n",
      "Gen Loss: 5.24303 Disc Loss: 0.374111 Q Losses: [0.029655676, 0.0027632394]\n",
      "Gen Loss: 4.36128 Disc Loss: 0.249981 Q Losses: [0.033417266, 0.0018204735]\n",
      "Gen Loss: 4.20281 Disc Loss: 0.39221 Q Losses: [0.025367158, 0.0017772139]\n",
      "Gen Loss: 3.09414 Disc Loss: 0.280021 Q Losses: [0.032148335, 0.0027093645]\n",
      "Gen Loss: 2.36959 Disc Loss: 0.524259 Q Losses: [0.038001947, 0.0034249136]\n",
      "Gen Loss: 1.07634 Disc Loss: 0.611994 Q Losses: [0.028737038, 0.00017748756]\n",
      "Gen Loss: 4.10209 Disc Loss: 0.178695 Q Losses: [0.025643939, 0.0040749828]\n",
      "Gen Loss: 4.73512 Disc Loss: 0.214353 Q Losses: [0.033109397, 0.00015517927]\n",
      "Gen Loss: 4.33596 Disc Loss: 0.231969 Q Losses: [0.033687688, 0.00020632961]\n",
      "Gen Loss: 4.92524 Disc Loss: 0.421371 Q Losses: [0.026851155, 0.0009844522]\n",
      "Saved Model on  73000\n",
      "Gen Loss: 4.61489 Disc Loss: 0.221634 Q Losses: [0.028184542, 0.00558047]\n",
      "Gen Loss: 3.86125 Disc Loss: 0.196019 Q Losses: [0.029150438, 0.016174644]\n",
      "Gen Loss: 3.1867 Disc Loss: 0.232133 Q Losses: [0.034588847, 0.039932981]\n",
      "Gen Loss: 6.53002 Disc Loss: 0.886827 Q Losses: [0.026148908, 0.0033529284]\n",
      "Gen Loss: 3.37339 Disc Loss: 0.338335 Q Losses: [0.03239987, 0.0013587868]\n",
      "Gen Loss: 3.38713 Disc Loss: 0.230736 Q Losses: [0.036086835, 0.00070892903]\n",
      "Gen Loss: 3.11963 Disc Loss: 0.386855 Q Losses: [0.030088712, 0.0014629227]\n",
      "Gen Loss: 6.27291 Disc Loss: 0.311782 Q Losses: [0.028726429, 0.0030174062]\n",
      "Gen Loss: 2.34649 Disc Loss: 0.451562 Q Losses: [0.031550352, 0.0046846853]\n",
      "Gen Loss: 3.86338 Disc Loss: 0.516132 Q Losses: [0.034419853, 0.014224059]\n",
      "Saved Model on  74000\n",
      "Gen Loss: 2.04761 Disc Loss: 0.517095 Q Losses: [0.034713559, 0.0024494512]\n",
      "Gen Loss: 3.61257 Disc Loss: 0.587532 Q Losses: [0.023739859, 0.0061082938]\n",
      "Gen Loss: 3.19512 Disc Loss: 0.421637 Q Losses: [0.027030705, 0.0012995191]\n",
      "Gen Loss: 2.15267 Disc Loss: 0.56867 Q Losses: [0.036491949, 0.0034864177]\n",
      "Gen Loss: 4.5448 Disc Loss: 0.449943 Q Losses: [0.025422581, 0.0020097457]\n",
      "Gen Loss: 4.64562 Disc Loss: 0.662999 Q Losses: [0.02508441, 0.0023204454]\n",
      "Gen Loss: 6.31925 Disc Loss: 0.266818 Q Losses: [0.029346226, 0.0035835556]\n",
      "Gen Loss: 3.70725 Disc Loss: 0.272665 Q Losses: [0.023716442, 0.020793781]\n",
      "Gen Loss: 6.98875 Disc Loss: 0.629383 Q Losses: [0.035708901, 0.00046063151]\n",
      "Gen Loss: 4.88518 Disc Loss: 0.127794 Q Losses: [0.022539323, 0.0013934316]\n",
      "Saved Model on  75000\n",
      "Gen Loss: 7.56184 Disc Loss: 1.06171 Q Losses: [0.047083039, 0.031461198]\n",
      "Gen Loss: 4.96844 Disc Loss: 0.400862 Q Losses: [0.030358281, 0.0096753268]\n",
      "Gen Loss: 0.279388 Disc Loss: 0.925408 Q Losses: [0.034448609, 0.00038415761]\n",
      "Gen Loss: 5.23511 Disc Loss: 0.247245 Q Losses: [0.02654732, 0.03471975]\n",
      "Gen Loss: 3.22865 Disc Loss: 0.287 Q Losses: [0.025704086, 0.00097916438]\n",
      "Gen Loss: 3.83714 Disc Loss: 0.263374 Q Losses: [0.031663075, 0.00012099863]\n",
      "Gen Loss: 5.04291 Disc Loss: 0.21598 Q Losses: [0.030892525, 0.0021842476]\n",
      "Gen Loss: 5.16749 Disc Loss: 0.418209 Q Losses: [0.023183711, 0.0066913343]\n",
      "Gen Loss: 4.15183 Disc Loss: 0.274393 Q Losses: [0.025759201, 0.0074145896]\n",
      "Gen Loss: 1.07656 Disc Loss: 0.524097 Q Losses: [0.023988008, 0.037185661]\n",
      "Saved Model on  76000\n",
      "Gen Loss: 3.55692 Disc Loss: 0.289578 Q Losses: [0.028772524, 0.0028115832]\n",
      "Gen Loss: 4.54603 Disc Loss: 0.223954 Q Losses: [0.054913983, 0.003318157]\n",
      "Gen Loss: 4.46582 Disc Loss: 0.243415 Q Losses: [0.031719178, 0.00042162847]\n",
      "Gen Loss: 4.59705 Disc Loss: 0.110819 Q Losses: [0.024511289, 0.00035885855]\n",
      "Gen Loss: 4.90775 Disc Loss: 0.743092 Q Losses: [0.029561043, 0.025992762]\n",
      "Gen Loss: 5.44717 Disc Loss: 0.475225 Q Losses: [0.030207809, 0.012676138]\n",
      "Gen Loss: 6.02748 Disc Loss: 0.231957 Q Losses: [0.042931862, 0.00023412083]\n",
      "Gen Loss: 5.54722 Disc Loss: 0.206133 Q Losses: [0.036666635, 0.00062929554]\n",
      "Gen Loss: 3.74743 Disc Loss: 0.327664 Q Losses: [0.037055906, 0.00043647373]\n",
      "Gen Loss: 6.40722 Disc Loss: 1.36754 Q Losses: [0.041671082, 0.00021764153]\n",
      "Saved Model on  77000\n",
      "Gen Loss: 5.38733 Disc Loss: 0.706326 Q Losses: [0.032762572, 0.0018224427]\n",
      "Gen Loss: 2.59968 Disc Loss: 0.229395 Q Losses: [0.030131608, 0.007506954]\n",
      "Gen Loss: 6.69287 Disc Loss: 0.304464 Q Losses: [0.028953185, 0.10218973]\n",
      "Gen Loss: 5.28752 Disc Loss: 0.275619 Q Losses: [0.029880868, 0.090537012]\n",
      "Gen Loss: 4.53622 Disc Loss: 0.333283 Q Losses: [0.024591368, 0.00085716933]\n",
      "Gen Loss: 5.27385 Disc Loss: 0.186329 Q Losses: [0.018498968, 0.0079833772]\n",
      "Gen Loss: 1.69183 Disc Loss: 0.382942 Q Losses: [0.030350791, 0.00041804661]\n",
      "Gen Loss: 5.88093 Disc Loss: 0.530198 Q Losses: [0.039218262, 0.0011522738]\n",
      "Gen Loss: 4.40991 Disc Loss: 0.205013 Q Losses: [0.024247389, 0.0010283077]\n",
      "Gen Loss: 5.38912 Disc Loss: 0.356772 Q Losses: [0.029067041, 0.0015108606]\n",
      "Saved Model on  78000\n",
      "Gen Loss: 4.77917 Disc Loss: 0.259386 Q Losses: [0.037035126, 0.00030137066]\n",
      "Gen Loss: 3.00764 Disc Loss: 0.294224 Q Losses: [0.030454289, 0.00018098946]\n",
      "Gen Loss: 6.56205 Disc Loss: 0.617177 Q Losses: [0.027317666, 0.00036714692]\n",
      "Gen Loss: 4.37163 Disc Loss: 0.244229 Q Losses: [0.021301519, 0.0049233316]\n",
      "Gen Loss: 2.55499 Disc Loss: 0.502672 Q Losses: [0.0359459, 0.0013541131]\n",
      "Gen Loss: 4.72675 Disc Loss: 0.403901 Q Losses: [0.034859762, 0.0025016621]\n",
      "Gen Loss: 5.02682 Disc Loss: 0.222013 Q Losses: [0.033419915, 0.00051691796]\n",
      "Gen Loss: 4.23202 Disc Loss: 0.240322 Q Losses: [0.027943024, 0.07832212]\n",
      "Gen Loss: 5.96919 Disc Loss: 0.673884 Q Losses: [0.025998477, 0.00084021396]\n",
      "Gen Loss: 3.17004 Disc Loss: 0.385681 Q Losses: [0.036612049, 0.00039799849]\n",
      "Saved Model on  79000\n",
      "Gen Loss: 4.59607 Disc Loss: 0.39831 Q Losses: [0.028641984, 0.0008861965]\n",
      "Gen Loss: 0.196002 Disc Loss: 1.42636 Q Losses: [0.03296826, 0.07469663]\n",
      "Gen Loss: 4.58241 Disc Loss: 0.214531 Q Losses: [0.034021214, 0.00039312261]\n",
      "Gen Loss: 5.27414 Disc Loss: 0.12491 Q Losses: [0.028202396, 0.00069280033]\n",
      "Gen Loss: 5.56544 Disc Loss: 0.480926 Q Losses: [0.026336689, 0.0049172631]\n",
      "Gen Loss: 5.33943 Disc Loss: 0.230118 Q Losses: [0.022365822, 0.00091023115]\n",
      "Gen Loss: 4.41768 Disc Loss: 0.223226 Q Losses: [0.027970986, 0.035735924]\n",
      "Gen Loss: 4.79815 Disc Loss: 0.304769 Q Losses: [0.024478212, 0.010601244]\n",
      "Gen Loss: 0.633295 Disc Loss: 0.562453 Q Losses: [0.035993472, 0.0019574852]\n",
      "Gen Loss: 3.99692 Disc Loss: 0.326006 Q Losses: [0.034422122, 0.0001686778]\n",
      "Saved Model on  80000\n",
      "Gen Loss: 3.99998 Disc Loss: 0.340373 Q Losses: [0.027277123, 0.023801234]\n",
      "Gen Loss: 4.90407 Disc Loss: 0.216019 Q Losses: [0.025501799, 0.00020508615]\n",
      "Gen Loss: 3.50644 Disc Loss: 0.460702 Q Losses: [0.029010188, 0.00019562161]\n",
      "Gen Loss: 3.98495 Disc Loss: 0.184865 Q Losses: [0.028536597, 0.011300226]\n",
      "Gen Loss: 4.71829 Disc Loss: 0.148665 Q Losses: [0.019008517, 0.002469972]\n",
      "Gen Loss: 6.42943 Disc Loss: 0.107495 Q Losses: [0.022449568, 5.5236371e-05]\n",
      "Gen Loss: 3.18972 Disc Loss: 0.227221 Q Losses: [0.026030052, 0.001642997]\n",
      "Gen Loss: -1.40018 Disc Loss: 0.832142 Q Losses: [0.02641844, 0.0024147134]\n",
      "Gen Loss: 5.82032 Disc Loss: 0.308336 Q Losses: [0.036598913, 0.0061093541]\n"
     ]
    }
   ],
   "source": [
    "# on at52 (GTX1080), 15mins/10000 epochs , 5000000 is about 12.5 hrs \n",
    "# https://stackoverflow.com/questions/19349410/how-to-pad-with-zeros-a-tensor-along-some-axis-python\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html\n",
    "# blow up after 81800\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\n",
    "# https://www.tensorflow.org/api_docs/python/tf/Session#run\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html\n",
    "    \n",
    "batch_size = 64 #Size of image batch to apply at each iteration.\n",
    "#iterations = 500000 #Total number of iterations to use.\n",
    "iterations = 81000 #Total number of iterations to use.\n",
    "sample_directory = './figsTut' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to save trained model to.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)\n",
    "    for i in range(iterations):\n",
    "        zs = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate a random z batch\n",
    "        lcat = np.random.randint(0,10,[batch_size,len(categorical_list)]) #Generate random c batch\n",
    "        lcont = np.random.uniform(-1,1,[batch_size,number_continuous]) #\n",
    "        \n",
    "        xs,_ = mnist.train.next_batch(batch_size) #Draw a sample batch from MNIST dataset.\n",
    "        xs = (np.reshape(xs,[batch_size,28,28,1]) - 0.5) * 2.0 #Transform it to be between -1 and 1\n",
    "        xs = np.lib.pad(xs, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1)) #Pad the images so the are 32x32\n",
    "        \n",
    "        _,dLoss = sess.run([update_D,d_loss],feed_dict={z_in:zs,real_in:xs,latent_cat_in:lcat,latent_cont_in:lcont}) #Update the discriminator\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs,latent_cat_in:lcat,latent_cont_in:lcont}) #Update the generator, twice for good measure.\n",
    "        _,qLoss,qK,qC = sess.run([update_Q,q_loss,q_cont_loss,q_cat_loss],feed_dict={z_in:zs,latent_cat_in:lcat,latent_cont_in:lcont}) #Update to optimize mutual information.\n",
    "        if i % 100 == 0:\n",
    "            print (\"Gen Loss: \" + str(gLoss) + \" Disc Loss: \" + str(dLoss) + \" Q Losses: \" + str([qK,qC]))\n",
    "            z_sample = np.random.uniform(-1.0,1.0,size=[100,z_size]).astype(np.float32) #Generate another z batch\n",
    "            lcat_sample = np.reshape(np.array([e for e in range(10) for _ in range(10)]),[100,1])\n",
    "            a = a = np.reshape(np.array([[(e/4.5 - 1.)] for e in range(10) for _ in range(10)]),[10,10]).T\n",
    "            b = np.reshape(a,[100,1])\n",
    "            c = np.zeros_like(b)\n",
    "            lcont_sample = np.hstack([b,c])\n",
    "            samples = sess.run(Gz,feed_dict={z_in:z_sample,latent_cat_in:lcat_sample,latent_cont_in:lcont_sample}) #Use new z to get sample images from generator.\n",
    "            if not os.path.exists(sample_directory):\n",
    "                os.makedirs(sample_directory)\n",
    "            #Save sample generator images for viewing training progress.\n",
    "            save_images(np.reshape(samples[0:100],[100,32,32]),[10,10],sample_directory+'/fig'+str(i)+'.png')\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
    "            print (\"Saved Model on \", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained network\n",
    "Once we have a trained model saved, we may want to use it to generate new images, and explore the representation it has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "INFO:tensorflow:Restoring parameters from ./models/model-80000.cptk\n"
     ]
    }
   ],
   "source": [
    "# http://qiita.com/TokyoMickey/items/f6a9251f5a59120e39f8\n",
    "\n",
    "sample_directory = './figsTut' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to load trained model from.\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(init)\n",
    "    #Reload the model.\n",
    "    print ('Loading Model...')\n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    \n",
    "    z_sample = np.random.uniform(-1.0,1.0,size=[100,z_size]).astype(np.float32) #Generate another z batch\n",
    "    lcat_sample = np.reshape(np.array([e for e in range(10) for _ in range(10)]),[100,1])\n",
    "    a = a = np.reshape(np.array([[(e/4.5 - 1.)] for e in range(10) for _ in range(10)]),[10,10]).T\n",
    "    b = np.reshape(a,[100,1])\n",
    "    c = np.zeros_like(b)\n",
    "    lcont_sample = np.hstack([b,c])\n",
    "    samples = sess.run(Gz,feed_dict={z_in:z_sample,latent_cat_in:lcat_sample,latent_cont_in:lcont_sample}) #Use new z to get sample images from generator.\n",
    "    if not os.path.exists(sample_directory):\n",
    "        os.makedirs(sample_directory)\n",
    "    #Save sample generator images for viewing training progress.\n",
    "    save_images(np.reshape(samples[0:100],[100,32,32]),[10,10],sample_directory+'/fig_test'+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dlpy35]",
   "language": "python",
   "name": "conda-env-dlpy35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
